[
    {
      "question": "傳統影像處理 (如銳利化) 和深度學習影像處理的主要區別是什麼？",
      "options": [
        "深度學習速度較慢",
        "傳統處理仰賴人為定義的演算法，深度學習從資料中自我學習",
        "深度學習只能做濾鏡",
        "傳統處理無法模糊化"
      ],
      "answer": 1,
      "description": "過去的圖像處理仰賴明確定義的演算法（銳利化、模糊化等） "
    },
    {
      "question": "根據速覽表，哪種模型「擅長生成自然感圖像」，且常用於 Deepfake？",
      "options": [
        "CNN (卷積神經網路)",
        "GAN (生成對抗網路)",
        "ViT (視覺變形金剛)",
        "CLIP (圖文對齊模型)"
      ],
      "answer": 1,
      "description": "表格顯示 GAN（生成對抗網路）「擅長生成自然感圖像」，其典型用途包括人臉編輯、上色、風格轉換、Deepfake。 "
    },
    {
      "question": "哪種模型透過學習語言與圖像的語意對應，能理解「圖像在說什麼」？",
      "options": [
        "Inpainting 模型",
        "擴散模型",
        "CNN",
        "CLIP"
      ],
      "answer": 3,
      "description": "CLIP（圖文對齊模型）「學習語言與圖像之間的語意對應，能理解『圖像在說什麼』」。 "
    },
    {
      "question": "擴散模型 (Diffusion Model) 生成圖像的主要方式是什麼？",
      "options": [
        "透過逐步去雜訊的方式生成",
        "透過兩個網路對抗",
        "提取局部特徵與紋理",
        "只處理局部缺損"
      ],
      "answer": 0,
      "description": "擴散模型「透過逐步去雜訊的方式生成圖像，過程可控且品質穩定」。 "
    },
    {
      "question": "CLIP 模型在 AI 圖像生成 (如 DALL·E, Stable Diffusion) 中扮演什麼關鍵角色？",
      "options": [
        "產生最終的圖像像素",
        "扮演「翻譯官」，將文字提示詞轉換成視覺創作的指導",
        "逐步去除雜訊",
        "修復圖像中的刮痕"
      ],
      "answer": 1,
      "description": "在圖像生成領域...CLIP 扮演著理解提示詞的重要角色，就像是 AI 的「翻譯官」，能夠將我們的文字指令轉換成視覺創作的指導。 "
    },
    {
      "question": "擴散模型 (Diffusion Model) 的「反向過程」(Reverse Diffusion) 是指什麼？",
      "options": [
        "逐步對清晰圖片增加雜訊",
        "逐步對雜訊圖片去除雜訊，使其變清晰",
        "讓兩個模型互相對抗",
        "將圖片切成小方塊"
      ],
      "answer": 1,
      "description": "「反向過程」(Reverse Diffusion) 對應的是去雜訊步驟，將混濁的墨跡（雜訊）一層層重新聚攏，直到恢復清晰。"
    },
    {
      "question": "文本提到擴散模型相較於 GAN 有什麼優勢？",
      "options": [
        "訓練速度快非常多",
        "不需要 GPU",
        "訓練過程不需要對抗，目標明確且穩定，不易「模式崩塌」",
        "只能生成黑白圖片"
      ],
      "answer": 2,
      "description": "GAN 的訓練像「貓捉老鼠」，容易失去平衡。擴散模型則不需要對抗，目標明確且穩定，且能避免 GAN 容易陷入的「模式崩塌」。"
    },
    {
      "question": "什麼是 Inpainting (圖像修補)？",
      "options": [
        "將圖片轉成黑白",
        "改變圖片的整體風格",
        "讓 AI 在指定的「留白」或遮罩區域，填補缺失的內容",
        "提高圖片的解析度"
      ],
      "answer": 2,
      "description": "所謂 Inpainting，就是讓 AI 在你指定的「留白」上即興演出...把缺失區域補得天衣無縫——不論是刪路人、補裂痕...都能一秒完成。 "
    },
    {
      "question": "在 Inpainting 流程中，「遮罩」(Mask) 的作用是什麼？",
      "options": [
        "決定圖片的風格",
        "提供要填補的新內容",
        "標示出哪些區域要保留 (黑色)，哪些區域要被 AI 重建 (白色)",
        "增加圖片的雜訊"
      ],
      "answer": 2,
      "description": "使用者先準備三樣素材：原圖、遮罩（白色代表要重建，黑色代表保留）以及可選的文字提示。 "
    },
    {
      "question": "視覺變形金剛 (ViT) 如何處理圖像？",
      "options": [
        "一次只看一個像素",
        "將圖像切成許多小方塊 (拼圖)，並使用自注意力機制讓它們「對話」",
        "只看圖像的邊緣",
        "它無法處理圖像，只能處理文字"
      ],
      "answer": 1,
      "description": "ViT 模仿人類視覺處理的方式，將圖像切成許多小方塊（就像把一張照片切成拼圖），然後讓這些方塊之間能夠互相「對話」。"
    },
    {
      "question": "視覺變形金剛 (ViT) 為什麼需要「位置標籤」(位置編碼)？",
      "options": [
        "為了改變圖像的顏色",
        "因為 Transformer 本身不知道方塊在圖像中的位置關係",
        "為了增加雜訊",
        "為了加快運算速度"
      ],
      "answer": 1,
      "description": "原本的 變形金剛 模型並不知道這些方塊在圖像中的位置關係，因此 ViT 會為每個方塊加上「位置標籤」，就像在每片拼圖背後標記位置資訊。"
    },
    {
      "question": "文本提到 AI 修復老照片主要包含哪三項任務？",
      "options": [
        "自動上色、刮痕修復、細節增強",
        "改變風格、加入文字、製作影片",
        "臉部偵測、背景移除、增加雜訊",
        "圖像分類、物體偵測、圖像分割"
      ],
      "answer": 0,
      "description": "AI 修復師有三項主要任務：自動上色（判斷天空、草地顏色）、刮痕修復（使用 Inpainting 補上缺損）、細節增強（使用超解析度）。"
    },
    {
      "question": "在老照片修復中，「超解析度」 (Super-Resolution) 技術主要用於哪個任務？",
      "options": [
        "自動上色",
        "刮痕修復",
        "細節增強，讓模糊的人臉與紋理變清晰",
        "移除路人"
      ],
      "answer": 2,
      "description": "「細節增強」涉及超解析度（Super-Resolution）技術，讓圖像放大後依然保有細節，讓模糊的人臉與衣物紋理重新變得清晰可見。"
    },
    {
      "question": "評估老照片修復效果時，文本提到了哪三個檢查面向？",
      "options": [
        "速度、大小、成本",
        "結構完整性、清晰度、自然度",
        "顏色數量、風格、檔案格式",
        "是否使用 ViT、GAN、CNN"
      ],
      "answer": 1,
      "description": "評估 AI 的表現，我們會從三個方面來檢查：結構完整性（不扭曲）、清晰度（細節）和自然度（效果自然）。 "
    },
    {
      "question": "文字生成圖像 (Text-to-Image) 依賴哪三種關鍵技術的結合？",
      "options": [
        "變形金剛 (理解文字)、擴散模型 (逐步繪製)、跨模態注意力機制 (參考知識)",
        "CNN、RNN、N-gram",
        "LoRA、ComfyUI、Sora",
        "Inpainting、GAN、ViT"
      ],
      "answer": 0,
      "description": "文本說明這類應用依賴三種關鍵技術：變形金剛（分解文字）、擴散模型（逐步去雜訊繪製）、跨模態注意力機制（建立概念聯繫）。"
    },
    {
      "question": "什麼是「風格轉換」 (Style Transfer)？",
      "options": [
        "將圖片變成黑白",
        "將一張圖片的「風格」(如筆觸、色彩) 套用到另一張圖片的「內容」上",
        "移除圖片中的物體",
        "生成全新的圖片"
      ],
      "answer": 1,
      "description": "風格轉換（Style Transfer）是一種將某張圖片的「風格」（如色彩、筆觸、質感）套用到另一張圖片上，同時保留其「內容」的技術。 "
    },
    {
      "question": "在技術上，風格轉換如何分離「內容」和「風格」？",
      "options": [
        "內容來自淺層特徵，風格來自深層特徵",
        "內容來自風格矩陣，風格來自 CNN",
        "使用 CNN 提取特徵，內容特徵接近原始圖片，風格特徵接近大師作品",
        "只能手動分離"
      ],
      "answer": 2,
      "description": "我們從一張隨機的圖片開始，不斷調整它，讓它同時滿足兩個條件：內容特徵要接近原始圖片，風格特徵要接近大師作品。 "
    },
    {
      "question": "在傳統美顏濾鏡中，「雙邊濾波」 (Bilateral Filter) 為何優於「高斯模糊」？",
      "options": [
        "雙邊濾波速度更快",
        "高斯模糊無法處理彩色",
        "雙邊濾波只對顏色相近的區域平滑，能保留臉部輪廓",
        "高斯模糊無法運作"
      ],
      "answer": 2,
      "description": "雙邊濾波...只對顏色相近的區域進行平滑處理，這樣就不會把臉部輪廓也模糊掉。"
    },
    {
      "question": "傳統美顏濾鏡如何「去除瑕疵」（如痘痘、法令紋）？",
      "options": [
        "改變整張臉的顏色",
        "使用「inpainting」技術，從臉的其他部分「借」皮膚來填補",
        "放大眼睛來轉移注意力",
        "增加高斯模糊"
      ],
      "answer": 1,
      "description": "它會先找出這些「高對比異常區域」...然後使用「inpainting」技術來填補。這就像是從臉的其他部分「借」一些皮膚來填補這些瑕疵。 "
    },
    {
      "question": "深度學習美顏中的「臉部語意分割」 (Face Parsing) 是指什麼？",
      "options": [
        "將臉部轉換成向量",
        "使用 CNN 對臉部進行精準分割，區分皮膚、眼睛、嘴唇等區域",
        "模糊整張臉",
        "移除背景"
      ],
      "answer": 1,
      "description": "這就像是給 AI 一套顯微手術刀，使用卷積神經網路對臉部進行精準分割。它能把你的臉分成不同的區域：這是皮膚、這是眼睛、這是嘴唇..."
    },
    {
      "question": "LoRA (Low-Rank Adaptation) 技術主要解決了 AI 圖像生成中的什麼問題？",
      "options": [
        "生成速度太慢",
        "圖片解析度太低",
        "難以保持角色或物體在不同圖像中的「長相一致性」",
        "只能生成黑白圖片"
      ],
      "answer": 2,
      "description": "LoRA 解決了主角的臉在每張圖裡都默默「跑偏」的問題，...把每個角色的獨特特徵寫進一份極小的「造型設定包」，以保持長相一致性。"
    },
    {
      "question": "LoRA 和 DreamBooth 相比，主要優勢是什麼？",
      "options": [
        "LoRA 會直接修改基礎模型，檔案很大",
        "LoRA 不會改動基礎模型，產生的「設定包」檔案極小且易於管理",
        "LoRA 不需要訓練",
        "LoRA 效果比較差"
      ],
      "answer": 1,
      "description": "DreamBooth 會直接修改...核心權重，...產生一個全新的模型檔案（通常 2-4 GB）。LoRA 則...既不去改動那個很大的基礎模型，也不犧牲生成速度。"
    },
    {
      "question": "文本中提到的 Civitai 是什麼？",
      "options": [
        "一種新的擴散模型",
        "OpenAI 開發的影片生成器",
        "一個最受歡迎的 LoRA 模型分享平台",
        "一種美顏濾鏡技術"
      ],
      "answer": 2,
      "description": "Civitai 是目前最受歡迎的 LoRA 分享平台之一，就像是 AI 藝術界的「亞馬遜書店」。 "
    },
    {
      "question": "什麼是 ComfyUI？",
      "options": [
        "一個 AI 圖像模型",
        "一個讓使用者像「拼樂高」一樣，用「節點」組合 AI 工作流的工具",
        "一個 LoRA 模型",
        "一個影片播放器"
      ],
      "answer": 1,
      "description": "ComfyUI...是一個超級方便的工具，讓你可以像拼樂高一樣，把各種 AI 模型和技術「積木」組合起來...ComfyUI 用「節點」（Node）來代表每一個步驟。 "
    },
    {
      "question": "人工智慧的「世界模型」 (World Model) 核心概念是什麼？",
      "options": [
        "一個儲存世界地圖的資料庫",
        "讓 AI 在腦海中建立一個可以運作的虛擬宇宙，以理解和預測真實世界的運作",
        "一個專門生成地球圖像的模型",
        "一個聊天機器人"
      ],
      "answer": 1,
      "description": "這就像是讓 AI 不僅能生成圖像，還能「想像」整個真實世界的運作方式，在腦海中建立一個可以運行的虛擬宇宙。"
    },
    {
      "question": "世界模型的三個核心組成部分是什麼？",
      "options": [
        "感知模型 (眼睛)、記憶模型 (大腦)、控制器 (決策中心)",
        "LoRA、ComfyUI、Sora",
        "CNN、GAN、ViT",
        "擴散、Inpainting、CLIP"
      ],
      "answer": 0,
      "description": "一個典型的世界模型通常由三個核心部分組成：感知模型（AI 的「眼睛」）、記憶模型（AI 的「大腦」）、控制器（AI 的「決策中心」）。"
    },
    {
      "question": "哪一個 OpenAI 模型被提及將世界模型應用於影片生成？",
      "options": [
        "CLIP",
        "DALL·E",
        "Sora",
        "GPT-4"
      ],
      "answer": 2,
      "description": "OpenAI 的 Sora 則將世界模型應用於影片生成。它不只是生成連續的圖像，而是理解整個場景的物理結構和動態變化。"
    },
    {
      "question": "文本提到 Sora 2 (相較於前代) 的一大突破是什麼？",
      "options": [
        "只能生成黑白影片",
        "整合了音訊生成，能創造與畫面完美同步的聲音，並考慮環境聲學特性",
        "影片長度只能 1 秒",
        "移除了對物理的理解"
      ],
      "answer": 1,
      "description": "Sora 2 的另一大突破是整合了音訊生成。它不只生成影像，還會同時創造出與畫面完美同步的聲音...這些聲音會考慮到環境的聲學特性。 "
    },
    {
      "question": "Sora 2 的「Cameo」技術指的是什麼？",
      "options": [
        "一種鏡頭運鏡術語",
        "一種安全地把自己的形象和聲音加入 AI 生成影片的功能",
        "影片中隱藏的浮水印",
        "一種新的擴散模型"
      ],
      "answer": 1,
      "description": "Sora 2 的「Cameo」技術，這是一個讓你安全地把自己的形象加入 AI 生成影片的功能。你可以上傳一段短影片和聲音樣本，讓 AI 學習你的長相和聲音。"
    },
    {
      "question": "為了防止濫用和深偽 (deepfake) 問題，Sora 2 採用了什麼措施？",
      "options": [
        "影片完全加密，無法觀看",
        "只生成公眾人物的影片",
        "在影片中嵌入浮水印和 C2PA 元資料，並過濾有害提示詞",
        "不提供任何安全措施"
      ],
      "answer": 2,
      "description": "Sora 2 在每一段生成的影片中都嵌入了浮水印和 C2PA 元資料（一種隱形的來源證明）...此外，系統還會過濾掉有害的提示詞，並限制生成公眾人物的影片。"
    }
  ]