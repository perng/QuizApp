[
    {
      "question": "根據文本，圖靈測試 (Turing Test) 是用來判斷什麼的？",
      "options": [
        "電腦的計算速度",
        "機器是否擁有人類智慧",
        "簡訊詐騙犯的真實身份",
        "AI 繪圖的精準度"
      ],
      "answer": 1,
      "description": "圖靈測試是說如果一個人和一台機器用文字聊天，如果這個人無法分辨和他聊天的是機器還是人，那麼就表示這台機器有了智慧。"
    },
    {
      "question": "文本中提到 AI 的「學習能力」特質，其主要的學習方式是什麼？",
      "options": [
        "像人類一樣理解抽象概念",
        "透過觀察大量的例子来找出規律",
        "透過背誦規則書來學習",
        "透過與人類聊天来學習"
      ],
      "answer": 1,
      "description": "AI能從大量數據中學習...不是像人類那樣理解概念，而是通過觀察大量的例子來找出規律。比如，當我們給AI看一萬張貓咪的照片時，它會仔細分析每張照片中的特徵...逐漸學會了「貓」的特徵。"
    },
    {
      "question": "文中提到 AI 的「模式識別」能力，但也指出其局限性，下列何者是該局限性的例子？",
      "options": [
        "AI 無法分辨貓和狗",
        "AI 可能找出「穿藍色襪子，股市就會上漲」這種無實際意義的關聯",
        "AI 只能在特定領域內靈活運用",
        "AI 下棋時不知道自己在玩遊戲"
      ],
      "answer": 1,
      "description": "這種能力有時也會鬧出笑話，比如「每次我穿藍色襪子，股市就會上漲」這種莫名其妙的關聯。這提醒我們，現在的AI雖然很會找規律，但它卻無法分辨這些規律是否有實際意義。"
    },
    {
      "question": "關於「生成式 AI」和「傳統 AI」的區別，下列敘述何者錯誤？",
      "options": [
        "傳統 AI 傾向給出明確答案，生成式 AI 則是創造全新內容",
        "傳統 AI 學習「分類」和「預測」，生成式 AI 學習「創造」",
        "傳統 AI 的結果通常是固定的，生成式 AI 的結果每次可能不一樣",
        "傳統 AI 應用於繪畫創作，生成式 AI 應用於垃圾郵件過濾"
      ],
      "answer": 3,
      "description": "傳統 AI 主要用在「判斷」和「預測」的場景，比如垃圾郵件過濾、股票預測。而生成式 AI 則用在「創造」的場景，比如寫作、繪畫、音樂創作。因此，(D) 選項的描述是相反的。"
    },
    {
      "question": "文本中提到 GPT 裡的 \"G\" 代表什麼？",
      "options": ["Google", "Generative (生成式)", "General (通用)", "Good (好的)"],
      "answer": 1,
      "description": "這就是 GPT (Generative Pre-trained Transformer) 裡的 'G'，它和傳統的 AI 有很大的不同。"
    },
    {
      "question": "下列哪一項不屬於文本所定義的人工智慧範疇？",
      "options": [
        "一個能觀察觀影習慣並推薦電影的系統",
        "機器學習 (Machine Learning)",
        "一個只會按設定類型（如愛情片）列出清單的系統",
        "大語言模型 (Large Language Model)"
      ],
      "answer": 2,
      "description": "一個系統只會按照你設定的類型（如日本片、愛情片、動作片）機械式地列出清單，這不是AI。另一個系統卻能觀察你的觀影習慣...這才是真正的AI！"
    },
    {
      "question": "機器學習 (Machine Learning) 是如何學習的？",
      "options": [
        "告訴電腦所有明確的規則",
        "讓電腦從資料中學習規律，並用規律做決策",
        "讓電腦背誦「騎車步驟123」",
        "機器學習是達成 AI 的唯一方法"
      ],
      "answer": 1,
      "description": "機器學習(Machine Learning, ML)是人工智慧的一個分支，它讓電腦學會從資料中學習規律，並且用這些規律来做出決策。"
    },
    {
      "question": "哪一種機器學習方式，像是「有老師天天盯著你唸書寫考卷」，需要提供題目（輸入）和正確答案（標籤）？",
      "options": [
        "監督式學習 (Supervised Learning)",
        "非監督式學習 (Unsupervised Learning)",
        "強化學習 (Reinforcement Learning)",
        "自監督學習 (Self-supervised Learning)"
      ],
      "answer": 0,
      "description": "監督式學習...就像是有老師天天盯著你唸書寫考卷。老師會給你題目（輸入），還會給你正確答案（標籤）。"
    },
    {
      "question": "哪一種機器學習方式，像是「從混沌的數據宇宙中，找出隱藏的規律和模式」，不需要資料標籤？",
      "options": [
        "監督式學習 (Supervised Learning)",
        "非監督式學習 (Unsupervised Learning)",
        "強化學習 (Reinforcement Learning)",
        "自監督學習 (Self-supervised Learning)"
      ],
      "answer": 1,
      "description": "非監督式學習就是這樣，從混沌的數據宇宙中，找出隱藏的規律和模式。不需要有人告訴你規則。"
    },
    {
      "question": "哪一種機器學習方式，被比喻為「AI界的周伯通」，會自己想出學習方法，例如把句子遮住幾個字來練習填空？",
      "options": [
        "監督式學習 (Supervised Learning)",
        "非監督式學習 (Unsupervised Learning)",
        "強化學習 (Reinforcement Learning)",
        "自監督學習 (Self-supervised Learning)"
      ],
      "answer": 3,
      "description": "自監督學習...這就像是一個超級自律的學生...他會把課本裡的句子遮住幾個字，然後自己試著填空...這種學習方式就是讓電腦自己給資料打標籤，然後自己學習。"
    },
    {
      "question": "在生物神經元結構中，負責接收來自其他神經元訊息的「接收天線」是？",
      "options": [
        "樹突 (dendrites)",
        "神經元細胞體 (neuron cell body)",
        "軸突 (axon)",
        "權重 (weights)"
      ],
      "answer": 0,
      "description": "樹突（dendrites）：想像這是神經元的「觸手」或「接收天線」！...樹突負責接收來自其他神經元的訊息。"
    },
    {
      "question": "在人工神經網路中，「參數」主要來自哪兩個部分？",
      "options": [
        "輸入層與輸出層",
        "權重 (weights) 和偏差值 (bias)",
        "CPU 與 GPU",
        "卷積層與池化層"
      ],
      "answer": 1,
      "description": "一個神經網路的參數數量，主要來自於兩個部分：權重（weights）和偏差值（bias）。"
    },
    {
      "question": "在訓練神經網路時，用來衡量系統推薦結果有多離譜（例如大熱天推薦薑母鴨）的機制，稱為什麼？",
      "options": [
        "正向傳遞 (Forward Propagation)",
        "損失函數 (Loss Function)",
        "反向傳播 (Back Propagation)",
        "梯度下降 (Gradient Descent)"
      ],
      "answer": 1,
      "description": "假設系統在大熱天推薦了薑母鴨，顧客立刻抗議...這個「差評」就是所謂的「損失函數」(Loss Function)，用來衡量系統推薦得有多離譜。"
    },
    {
      "question": "在神經網路訓練中，從目前的損失值反推回去，找一條最陡峭的向下路徑來調整權重，以最小化損失值的過程，稱為什麼？",
      "options": [
        "梯度下降 (Gradient Descent)",
        "過擬合 (Overfitting)",
        "閒置神經元 (Idle neuron)",
        "正向傳遞 (Forward Propagation)"
      ],
      "answer": 0,
      "description": "反向傳播的目的就是要從目前的損失值，反推回去，找一條最陡峭的向下路徑...使得損失值愈來愈小，這就是所謂的「梯度下降」(Gradient Descent)。"
    },
    {
      "question": "如果一個 AI 模型把訓練資料的每個細節都記住了，但遇到新的情況就完全不會處理，這種現象稱為什麼？",
      "options": [
        "欠擬合 (Underfitting)",
        "過擬合 (Overfitting)",
        "梯度消失 (Gradient Vanishing)",
        "反向傳播 (Back Propagation)"
      ],
      "answer": 1,
      "description": "過擬合(overfitting)就像是十長老的學習方式，AI把訓練資料的每個細節都記住了，但遇到新的情況就完全不會處理。"
    },
    {
      "question": "如果一個 AI 模型的參數太少（腦容量太小），就算給它再多的資料也記不住多少東西，這種現象稱為什麼？",
      "options": [
        "欠擬合 (Underfitting)",
        "過擬合 (Overfitting)",
        "梯度爆炸 (Gradient Explosion)",
        "交叉驗證 (Cross-validation)"
      ],
      "answer": 0,
      "description": "如果模型的參數太少（腦容量太小），就算給它再多的資料（再厚的課本），它也記不住多少東西，這就是欠擬合。"
    },
    {
      "question": "下列何者不是文本中提到用來避免「過擬合」的方法？",
      "options": [
        "正則化 (Regularization)",
        "早停法 (Early stopping)",
        "增加模型複雜度（增加參數量）",
        "資料擴增 (Data augmentation)"
      ],
      "answer": 2,
      "description": "防止欠擬合，我們可以增加模型的複雜度。而正則化、早停法、資料擴增等都是用來防止「過擬合」的。"
    },
    {
      "question": "卷積神經網路 (CNN) 特別擅長處理哪一類型的資料？",
      "options": [
        "具有空間結構的資料（如圖片）",
        "純文字資料",
        "聲音訊號",
        "股票市場數據"
      ],
      "answer": 0,
      "description": "CNN 特別擅長處理像圖片這種具有「空間結構」的資料。"
    },
    {
      "question": "在 CNN 中，如同「專業找碴小分隊」，負責拿著放大鏡掃描圖片、偵測特定圖案（如直線、圓弧）的層級是？",
      "options": [
        "池化層 (Pooling Layer)",
        "卷積層 (Convolutional Layer)",
        "隱藏層 (Hidden Layer)",
        "輸出層 (Output Layer)"
      ],
      "answer": 1,
      "description": "第一組：專業「找碴」小分隊（卷積層）...想像派出一堆「偵探」...有的專門找「直線」、有的專門找「橫線」。"
    },
    {
      "question": "在 CNN 中，如同「摘要小能手」，負責將偵探地圖化繁為簡、抓重點（例如只保留最大值）的層級是？",
      "options": [
        "池化層 (Pooling Layer)",
        "卷積層 (Convolutional Layer)",
        "輸入層 (Input Layer)",
        "全連接神經網路 (Fully Connected NN)"
      ],
      "answer": 0,
      "description": "第二組：抓重點「摘要」小能手（池化層）...幫忙抓重點、化繁為簡。這個小能手會把地圖分成一小格一小格，然後在每一格裡只挑出最重要的那個記號。"
    },
    {
      "question": "文本提到，深度學習 (Deep Learning) 相較於傳統機器學習的主要優勢是什麼？",
      "options": [
        "只需要很少的訓練資料",
        "訓練速度非常快",
        "能夠自動學習特徵，不需要人工進行「特徵工程」",
        "完全不會有「過擬合」的問題"
      ],
      "answer": 2,
      "description": "深度學習的厲害之處在於...它能夠自動學習這些特徵！...這時研究人員都驚嘆「這個模型可以用了，可是我完全不知道它是怎樣做到的」。"
    },
    {
      "question": "文本中提到，2015 年發明了「跳層連接」(ResNet)，一口氣將神經網路蓋到 152 層，解決了什麼主要問題？",
      "options": [
        "梯度消失 (Gradient Vanishing)",
        "資料量不足",
        "計算能力不夠",
        "過擬合 (Overfitting)"
      ],
      "answer": 0,
      "description": "再往上蓋就會遇到一個奇怪的「梯度消失」的問題...2015年的ResNet，它發明了「跳層連接」（像是在大樓中加入快速電梯），一口氣蓋到152層！"
    },
    {
      "question": "「生成對抗網路」(GAN) 是由哪兩個AI互相較勁組成的？",
      "options": [
        "卷積層與池化層",
        "生成器 (Generator) 與判別器 (Discriminator)",
        "監督式學習與非監督式學習",
        "智慧代理與環境"
      ],
      "answer": 1,
      "description": "這個系統由兩個 AI 組成，一個叫「生成器」，另一個叫「判別器」。"
    },
    {
      "question": "在 GAN 的比喻中，米格倫 (Han van Meegeren) 扮演了什麼角色？",
      "options": [
        "判別器 (Discriminator)，負責鑑定真假",
        "生成器 (Generator)，負責製造逼真的仿作",
        "損失函數 (Loss Function)，負責評估錯誤",
        "智慧代理 (Intelligent Agent)，負責與環境互動"
      ],
      "answer": 1,
      "description": "一個AI扮演「米格倫」，專門製造逼真的仿作（比如假畫）...另一個AI扮演「鑑定師」，負責識破真假。前者是生成器，後者是判別器。"
    },
    {
      "question": "文本中提到「深度偽造」(Deepfake) 技術，是哪一種 AI 技術被濫用的隱憂？",
      "options": [
        "卷積神經網路 (CNN)",
        "強化學習 (Reinforcement Learning)",
        "對抗式學習 (Adversarial Learning) / GAN",
        "監督式學習 (Supervised Learning)"
      ],
      "answer": 2,
      "description": "對抗式學習也帶來一些擔憂...更可怕的是「深度偽造」(Deepfake)技術。這種技術可以讓你的臉出現在你從沒去過的地方。"
    },
    {
      "question": "哪一種機器學習方法，是在沒有標註資料、必須與環境互動的情況下，透過「試錯學習」和「獎勵處罰機制」來學習的？",
      "options": [
        "監督式學習 (Supervised Learning)",
        "非監督式學習 (Unsupervised Learning)",
        "強化學習 (Reinforcement Learning)",
        "自監督學習 (Self-supervised Learning)"
      ],
      "answer": 2,
      "description": "如果一開始連資料都沒有...這時候就需要用到「強化學習」(Reinforcement Learning)了。強化學習就像是一個「試錯學習」的過程... AI的目標，就是...最大化它能得到的總獎勵。"
    },
    {
      "question": "在強化學習的「世紀帝國二」例子中，「家裡還有多少木材、食物、黃金」屬於五個核心元素中的哪一個？",
      "options": [
        "智慧代理 (Intelligent Agent)",
        "環境 (Environment)",
        "狀態 (State)",
        "動作 (Action)"
      ],
      "answer": 2,
      "description": "第三是「狀態」（State），這描述了AI當前的處境。在「世紀帝國」裡，狀態可是超級複雜的！包括：家裡還有多少木材、食物、黃金、石頭？"
    },
    {
      "question": "在強化學習中，AI 面臨「要探索新的可能性，還是利用已知的好方法？」的難題，這被稱為什麼？",
      "options": [
        "探索-利用困境 (Exploration-Exploitation Dilemma)",
        "梯度消失問題 (Gradient Vanishing Problem)",
        "過擬合 (Overfitting)",
        "獎勵稀疏性 (Reward Rarity)"
      ],
      "answer": 0,
      "description": "在強化學習過程中，AI面臨著一個...難題：是要探索新的可能性，還是利用已知的好方法？ 這個問題在技術上被稱為「探索-利用困境」。"
    },
    {
      "question": "目前如 ChatGPT、Google Gemini 等 AI 系統，雖然功能強大，但仍被歸類為：",
      "options": [
        "通用人工智慧 (AGI)",
        "狹義人工智慧 (Narrow AI)",
        "生物神經網路 (Biological Neural Network)",
        "偽畫 AI (Forgery AI)"
      ],
      "answer": 1,
      "description": "我們今天所使用的 AI（像是 OpenAI 的 ChatGPT、Google 的 Gemini...）...仍然被稱為狹義 AI（Narrow AI），因為它們主要針對特定任務或領域進行訓練和優化。"
    },
    {
      "question": "根據文本，「通用人工智慧」(AGI) 與目前 AI 最大的不同在於：",
      "options": [
        "AGI 計算速度更快",
        "AGI 能畫出更逼真的圖片",
        "AGI 具有像人類一樣多面向的智慧，能真正理解世界並自主學習",
        "AGI 只需要更少的電力"
      ],
      "answer": 2,
      "description": "AGI 則是一種完全不同層次的智慧體。它能夠真正理解世界和人類...具有自我意識...能夠自主學習和創新...具有人類級別的通用智慧。"
    },
    {
      "question": "電腦以及人工智慧的祖師爺是誰？",
      "options": [
        "圖靈 (Alan Turing)",
        "伊恩·古德費洛 (Ian Goodfellow)",
        "黃仁勳 (Jensen Huang)",
        "漢·凡·米格倫 (Han van Meegeren)"
      ],
      "answer": 0,
      "description": "電腦以及人工智慧的 祖師爺圖靈(Alan Turing) 在1950年就提出了很有趣的圖靈測試。"
    },
    {
      "question": "AI的四個重要特質是學習能力、模式識別、決策能力以及什麼？",
      "options": [
        "適應能力 (Adaptation)",
        "創造能力 (Creativity)",
        "情感能力 (Emotion)",
        "社交能力 (Socialization)"
      ],
      "answer": 0,
      "description": "真正的AI具備一些重要特質...首先是學習能力...接著是適應能力...再來是模式識別...最後是決策能力。"
    },
    {
      "question": "機器學習是 AI 的一個分支，而什麼又是機器學習的一個分支？",
      "options": [
        "神經網路 (Neural Network)",
        "深度偽造 (Deepfake)",
        "特徵工程 (Feature Engineering)",
        "卷積核 (Convolution Kernel)"
      ],
      "answer": 0,
      "description": "機器學習(Machine Learning, ML)是人工智慧的一個分支...而神經網路 (Neural Network)又是機器學習的一個分支。"
    },
    {
      "question": "在神經網路訓練中，根據錯誤反向調整權重的過程稱為？",
      "options": [
        "反向傳播 (Back Propagation)",
        "正向傳遞 (Forward Propagation)",
        "損失函數 (Loss Function)",
        "模式識別 (Pattern Recognition)"
      ],
      "answer": 0,
      "description": "然後就來到最重要的「反向傳播」（Back Propagation）階段。系統會像個認真檢討的實習生，從後往前找出問題出在哪裡。"
    },
    {
      "question": "在 CNN 中，負責偵測特定圖案的小矩陣被稱為什麼？",
      "options": [
        "卷積核 (Convolution Kernel)",
        "池化層 (Pooling Layer)",
        "偏差值 (Bias)",
        "樹突 (Dendrite)"
      ],
      "answer": 0,
      "description": "這些小矩陣就是所謂的「卷積核」(Convolution Kernel)，它們就像是偵探的「專業技能」，專門用來偵測特定的圖案。"
    },
    {
      "question": "在 CNN 的池化層中，最常用的方式是？",
      "options": [
        "最大池化 (Max Pooling)",
        "平均池化 (Average Pooling)",
        "最小池化 (Min Pooling)",
        "隨機池化 (Random Pooling)"
      ],
      "answer": 0,
      "description": "最大池化（Max Pooling）：就像是在每個小區塊中找出「最可疑」的那個點，保留最大值。這是最常用的方式。"
    },
    {
      "question": "神經網路層數過多時，數值衰減成零稱為？",
      "options": [
        "梯度消失 (Gradient Vanishing)",
        "梯度爆炸 (Gradient Explosion)",
        "過擬合 (Overfitting)",
        "欠擬M合 (Underfitting)"
      ],
      "answer": 0,
      "description": "所謂的「梯度消失」就是在神經網路中傳遞的數值在傳了若干層之後衰減成零了。"
    },
    {
      "question": "「生成對抗網路」 (GAN) 的概念是由誰提出的？",
      "options": [
        "Ian Goodfellow",
        "Alan Turing",
        "Han van Meegeren",
        "Geoffrey Hinton"
      ],
      "answer": 0,
      "description": "這就是著名的「生成對抗網路」(Generative Adversarial Network, GAN)的概念，由Ian Goodfellow在2014年提出。"
    },
    {
      "question": "在強化學習中，負責學習的 AI 對手被稱為？",
      "options": [
        "智慧代理 (Intelligent Agent)",
        "環境 (Environment)",
        "判別器 (Discriminator)",
        "生成器 (Generator)"
      ],
      "answer": 0,
      "description": "首先是「智慧代理」（Intelligent Agent），這就是那個要學習怎麼打贏你的AI對手啦！"
    },
    {
      "question": "在強化學習中，將經驗存儲在記憶庫中再隨機抽樣學習的機制，稱為？",
      "options": [
        "經驗回放 (Experience Replay)",
        "自監督學習 (Self-supervised Learning)",
        "反向傳播 (Back Propagation)",
        "探索-利用 (Exploration-Exploitation)"
      ],
      "answer": 0,
      "description": "為了提高學習效率，現代的強化學習算法常常使用「經驗回放」（Experience Replay）機制。...AI會將經歷過的...組合存儲在一個記憶庫中。在學習時，它會隨機抽取一些經驗進行學習。"
    }
  ]