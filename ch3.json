[
    {
      "question": "大語言模型訓練的「國民教育」階段指的是什麼？",
      "options": [
        "資料準備與清洗",
        "預訓練 (Pre-training)",
        "監督式微調",
        "人類反饋強化 (RLHF)"
      ],
      "answer": 1,
      "description": "文本將「預訓練」比喻為國民教育，這是模型打基礎的階段，從大量文本中學習語言規則和常識。"
    },
    {
      "question": "文本中提到哪個社群平台因其無厘頭問題，對訓練中文大語言模型有特殊幫助？",
      "options": [
        "PTT八卦版",
        "知乎",
        "弱智吧",
        "維基百科"
      ],
      "answer": 2,
      "description": "「弱智吧」因充滿刁鑽的無厘頭問題（如「隕石為什麼每次都能精準地砸中隕石坑?」），可以讓大語言模型適應這類問題，因此有特殊幫助。"
    },
    {
      "question": "COCO (Common Objects in Context) 這樣的資料集主要用於訓練 AI 的哪種能力？",
      "options": [
        "程式編碼",
        "學術論文理解",
        "多模態（圖像和文字配對）",
        "音訊處理"
      ],
      "answer": 2,
      "description": "COCO 資料集包含了大量的圖片和對應的文字描述，屬於多模態資料，幫助 AI 學習理解圖像內容。"
    },
    {
      "question": "在資料處理階段，將「氣死我了」修正為正確用字，避免 AI 學習錯別字，屬於哪個環節？",
      "options": [
        "去除雜質",
        "格式統一",
        "語言清理",
        "資料標註"
      ],
      "answer": 2,
      "description": "這屬於「語言清理」環節，目的是修正錯別字，以免 AI 也輸出錯別字。"
    },
    {
      "question": "將醫療記錄中的「張小明」改為「患者A」，「竹北市」改為「台灣北部」，這是什麼措施？",
      "options": [
        "資料標註",
        "資料隱私保護（匿名化）",
        "資料平衡性處理",
        "格式統一"
      ],
      "answer": 1,
      "description": "這是資料隱私保護中的「匿名化」或「脫敏」處理，移除或模糊化個人識別資訊，同時保留學習價值。"
    },
    {
      "question": "大語言模型的「預訓練」(Pre-training) 階段，主要目標是什麼？",
      "options": [
        "學習特定問答技巧",
        "讓模型學會人類的品味",
        "理解語言基本規則和積累常識",
        "壓縮模型大小"
      ],
      "answer": 2,
      "description": "預訓練是 AI 學習的第一階段，主要目標是讓模型理解語言的基本規則、積累大量知識，以及學會預測和推理。"
    },
    {
      "question": "什麼是 RLHF (人類反饋強化)？",
      "options": [
        "讓 AI 讀遍網路上的所有資料",
        "透過人類對 AI 的回答進行排名，訓練 AI 學習人類的偏好",
        "將大模型的知識壓縮到小模型",
        "移除 AI 神經網路中不活躍的部分"
      ],
      "answer": 1,
      "description": "RLHF 就像一個「情商訓練營」，透過人類評審對 AI 的回答進行評分或排名，然後訓練一個「獎勵模型」去學習人類的喜好，最後強化 AI 主模型以產生更討喜的回答。"
    },
    {
      "question": "在 RLHF 中，那個學會了人類偏好並負責給 AI 回答打分數的模型叫什麼？",
      "options": [
        "老師模型 (Teacher Model)",
        "學生模型 (Student Model)",
        "獎勵模型 (Reward Model)",
        "門控網路 (Gating Network)"
      ],
      "answer": 2,
      "description": "這個模型叫做「獎勵模型」（Reward Model，RM），它的任務是學習人類評審的喜好，並預測一個回答能得到多少「讚」。"
    },
    {
      "question": "「知識蒸餾」(Knowledge Distillation) 是指什麼？",
      "options": [
        "AI 學習如何調酒",
        "將一個龐大的「老師模型」的知識精華，傳授給一個輕巧的「學生模型」",
        "AI 產生了虛構的知識",
        "刪除模型中無用的參數"
      ],
      "answer": 1,
      "description": "知識蒸餾就像武俠小說中的「傳功」，將一個強大但龐大的老師模型的「武功心法」（軟標籤）傳授給一個小型的學生模型。"
    },
    {
      "question": "DistilBERT 是如何被創造出來的？",
      "options": [
        "透過模型剪枝 BERT",
        "透過知識蒸餾 BERT",
        "透過模型量化 BERT",
        "它是一個全新的架構"
      ],
      "answer": 1,
      "description": "DistilBERT 是 Hugging Face 團隊透過「知識蒸餾」大法，從 BERT（老師模型）訓練出來的「徒弟模型」，體積更小、速度更快。"
    },
    {
      "question": "「模型剪枝」(Pruning) 是在做什麼？",
      "options": [
        "將 AI 的知識傳授給小模型",
        "降低 AI 數字的精確度",
        "移除 AI 模型中那些「混吃等死」、幾乎不工作的神經元或連接",
        "讓 AI 學習園藝"
      ],
      "answer": 2,
      "description": "模型剪枝就是找出並移除模型中那些貢獻很小或從不工作的「無用員工」（神經元連接），讓模型更精簡高效。"
    },
    {
      "question": "「模型量化」(Quantization) 是如何壓縮模型的？",
      "options": [
        "刪除神經元",
        "將 AI 的知識傳授給小模型",
        "移除重複的資料",
        "降低模型儲存數字的精確度，例如從 FP32 降到 INT8"
      ],
      "answer": 3,
      "description": "量化就像是把儲存數字的「尺」變粗，降低其精確度（例如從 32 位元浮點數降到 8 位元整數），從而讓模型檔案變小、運算變快。"
    },
    {
      "question": "什麼是「遷移學習」(Transfer Learning)？",
      "options": [
        "AI 學習如何從一個地方移動到另一個地方",
        "利用已經學好的通用能力（預訓練模型），來加速學習特定任務",
        "將 AI 模型從一台電腦轉移到另一台",
        "AI 學習不同語言間的翻譯"
      ],
      "answer": 1,
      "description": "遷移學習就像學會騎腳踏車後，能更快學會騎摩托車，因為「平衡感」這個核心技能被「遷移」過去了。在 AI 中，就是利用預訓練好的模型來加速新任務的學習。"
    },
    {
      "question": "「微調」(Fine-tuning) 與「從零開始訓練」相比，有什麼優勢？",
      "options": [
        "模型一定會更小",
        "模型一定會更聰明",
        "成本更低，因為利用了預訓練模型的基礎能力",
        "不需要 GPU"
      ],
      "answer": 2,
      "description": "微調是實現遷移學習的主要手段，它利用了預訓練模型的基礎，因此相對於從零開始訓練，成本（時間、金錢、算力）都相對低很多。"
    },
    {
      "question": "如果微調的調整太過激進，可能導致什麼問題？",
      "options": [
        "模型沒有任何改變",
        "災難性遺忘 (Catastrophic Forgetting)",
        "模型參數變多",
        "模型運算變慢"
      ],
      "answer": 1,
      "description": "文本提到，太過激進的調整可能導致「災難性遺忘」，就像為了學新語言把母語忘了。"
    },
    {
      "question": "「多模態學習」(Multimodal Learning) 讓 AI 具備什麼能力？",
      "options": [
        "只理解文字",
        "同時理解和處理不同類型的資訊，如圖像、聲音和文字",
        "說多種語言",
        "產生幻覺"
      ],
      "answer": 1,
      "description": "多模態學習讓 AI 模仿人類的全方位認知，能夠同時理解圖像、聲音、文字等不同「模態」的資訊。"
    },
    {
      "question": "多模態模型（如 GPT-4o, Gemini 2.5 Pro）展現了什麼趨勢？",
      "options": [
        "模型越來越只專注於文字",
        "即時多模態互動（語音/視訊）、電腦操作、長上下文推理",
        "模型體積越來越小",
        "不再需要 GPU"
      ],
      "answer": 1,
      "description": "文本總結了三大趨勢：（1）即時多模態（自然的語音/視訊互動）；（2）電腦操作（從「回答問題」到「完成任務」）；（3）長上下文推理（更強的跨模態整合能力）。"
    },
    {
      "question": "「專家混合」(Mixture of Experts, MoE) 架構是如何運作的？",
      "options": [
        "將所有專家融合成一個超級專家",
        "讓 AI 隨機選擇一個專家來回答",
        "透過「門控網路」根據問題性質，選擇最適合的幾個專家來處理",
        "讓所有專家同時回答並投票"
      ],
      "answer": 2,
      "description": "MoE 像一個「任務分配中心」，由一個「門控網路」（Gating Network）指揮官，根據問題性質，決定要派哪些專精特定領域的「專家」上場。"
    },
    {
      "question": "Mixtral 8x7B 和 DeepSeek-V3 都是什麼架構的例子？",
      "options": [
        "RNN (遞迴神經網路)",
        "知識蒸餾 (Knowledge Distillation)",
        "專家混合 (Mixture of Experts)",
        "模型剪枝 (Pruning)"
      ],
      "answer": 2,
      "description": "Mixtral 和 DeepSeek-V3/R1 都是採用專家混合（MoE）架構的著名模型，它們擁有多個專家（分別為 8 個和 256 個）。"
    },
    {
      "question": "調整大語言模型的「溫度」(Temperature) 參數，主要是在控制什麼？",
      "options": [
        "AI 的運算速度",
        "AI 的記憶體用量",
        "AI 的「創造力」與「準確性」之間的平衡",
        "AI 消耗的電力"
      ],
      "answer": 2,
      "description": "溫度就像 AI 的「創造力開關」。低溫（接近0）時，AI 回答更準確、理性；高溫（接近1）時，AI 回答更具創意和多樣性。"
    },
    {
      "question": "如果你需要 AI 幫你「撰寫技術文檔」或「生成程式碼」，你應該設定：",
      "options": [
        "較低的溫度 (0.1-0.3)",
        "中等的溫度 (0.4-0.7)",
        "較高的溫度 (0.8-1.0)",
        "溫度不影響"
      ],
      "answer": 0,
      "description": "對於需要高準確性的任務，如技術文檔或程式碼，建議使用較低的溫度，讓 AI 變得「冷靜」和「理性」，選擇最可能、最安全的回答。"
    },
    {
      "question": "為什麼訓練 AI 大模型主要使用 GPU 而不是 CPU？",
      "options": [
        "GPU 比較便宜",
        "GPU 更省電",
        "GPU 擅長大規模並行運算（矩陣運算），而 CPU 適合處理複雜的單一任務",
        "CPU 無法執行 AI 程式"
      ],
      "answer": 2,
      "description": "GPU 擁有數千個核心，能像「千手觀音」一樣同時處理成千上萬個簡單計算（如矩陣運算），這正是 AI 訓練所需要的；而 CPU 核心少，適合處理複雜的序列任務。"
    },
    {
      "question": "NVIDIA 的 CUDA 是什麼？",
      "options": [
        "一種新型的 GPU 硬體",
        "一個讓開發者能指揮 NVIDIA GPU 進行運算的程式庫和開發平台",
        "AMD 的 GPU 加速技術",
        "Google 的 AI 專用晶片"
      ],
      "answer": 1,
      "description": "CUDA 是 NVIDIA 為自家 GPU 量身打造的「獨門內功心法」，是一個程式庫和開發平台，讓開發者能用 C++ 或 Python 等語言指揮 GPU 進行並行運算。"
    },
    {
      "question": "NVIDIA 的 NVLink 技術主要解決了什麼問題？",
      "options": [
        "GPU 運算速度不夠快",
        "單張 GPU 記憶體不足，需要多張 GPU 高速協作",
        "CPU 和 GPU 之間的通訊",
        "AI 產生幻覺"
      ],
      "answer": 1,
      "description": "訓練大模型時，單張 GPU 記憶體不夠。NVLink 是一種高速互連技術，像「超級高速公路」，讓多張 GPU 可以無延遲地共享資料和記憶體，協同作戰。"
    },
    {
      "question": "Google 專門為 AI 運算設計的「煉丹爐」晶片叫什麼？",
      "options": [
        "GPU (圖形處理器)",
        "TPU (張量處理器)",
        "ROCm",
        "Ascend (昇騰)"
      ],
      "answer": 1,
      "description": "TPU（張量處理器）是 Google 專門為深度學習（張量運算）設計的 AI 加速器，就像是專用的「煉丹爐」。"
    },
    {
      "question": "華為的昇騰 (Ascend) 晶片集群採用了什麼技術來實現節點間的高速數據傳輸？",
      "options": [
        "NVLink",
        "PCIe 5.0",
        "光通信技術",
        "藍牙"
      ],
      "answer": 2,
      "description": "華為在節點間的數據傳輸上採用了「光通信技術」，就像用光速傳遞訊號，比傳統電信號快得多。"
    },
    {
      "question": "AI 的「規模法則」(Scaling Laws) 指的是什麼？",
      "options": [
        "模型越大，運算越慢",
        "模型越大，幻覺越多",
        "模型表現與「參數數量」、「訓練資料量」和「計算資源」成正比",
        "模型越小，越省電"
      ],
      "answer": 2,
      "description": "規模法則是指模型表現通常與投入的資源（參數、資料、算力）成正比，即「大力出奇蹟」。"
    },
    {
      "question": "規模法則中的「對數關係」 (logarithmic) 意味著什麼？",
      "options": [
        "投入加倍，性能加倍",
        "越到後期，要提升一點點性能，需要付出的資源代價不成比例地暴增",
        "模型越大，越容易訓練",
        "投入越多，性能反而下降"
      ],
      "answer": 1,
      "description": "對數關係意味著性能提升會越來越難。從 60 分到 80 分可能花幾百萬，但從 80 分到 90 分可能要花上億，每提升一點所需的代價呈指數級增長。"
    },
    {
      "question": "文本提到 DeepSeek V3 挑戰了規模法則的哪個面向？",
      "options": [
        "證明了模型越大越笨",
        "證明了不需要 GPU 也能訓練",
        "證明了「鈔能力」是唯一解",
        "證明了靠更聰明的設計和高效訓練，也能在規模相對較小的情況下實現高效能"
      ],
      "answer": 3,
      "description": "DeepSeek V3 證明了「不是只有花錢才有出路」，透過更好的模型設計（如 MoE）、更乾淨的資料和高效訓練，也能與參數大得多的模型競爭。"
    },
    {
      "question": "本章小結中，將「遷移學習」和「微調」比喻為什麼？",
      "options": [
        "吃的不能馬虎",
        "體重管理很重要",
        "站在巨人肩膀上最省力",
        "神兵利器不可少"
      ],
      "answer": 2,
      "description": "小結中將「遷移學習」和「微調」比喻為「站在巨人肩膀上最省力」，因為這比從零開始練小號的效率高得多。"
    }
  ]