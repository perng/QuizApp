[
    {
      "question": "語言模型 (Language Model) 最基本的核心任務是什麼？",
      "options": [
        "回答哲學問題",
        "理解人類情感",
        "預測下一個最可能出現的詞",
        "翻譯所有語言"
      ],
      "answer": 2,
      "description": "語言模型的核心目標是根據上下文預測下一個最可能出現的詞，從而生成自然流暢的語句。"
    },
    {
      "question": "N-gram 模型最大的缺點是什麼？",
      "options": [
        "計算速度太快",
        "無法處理中文",
        "記憶力很差，無法處理長距離的詞語依賴",
        "需要神經網路"
      ],
      "answer": 2,
      "description": "N-gram 模型只能觀察固定範圍內的詞，因此無法掌握長距離的語意關聯，導致記憶力不足。"
    },
    {
      "question": "為什麼早期的神經網路無法分辨「我砍你」和「你砍我」？",
      "options": [
        "因為它們沒有足夠的參數",
        "因為它們處理時丟失了字詞的順序",
        "因為它們沒有使用詞嵌入",
        "因為它們是閉源的"
      ],
      "answer": 1,
      "description": "古典神經網路常將輸入視為一組無序的數值，只要組成元素相同就會得到相同的結果，導致詞序被忽略。"
    },
    {
      "question": "遞迴神經網路 (RNN) 嘗試解決什麼問題？",
      "options": [
        "將詞語順序納入考慮",
        "讓模型變更大",
        "讓 AI 產生幻覺",
        "評估模型的好壞"
      ],
      "answer": 0,
      "description": "RNN 透過循環結構保留歷史資訊，使模型能依序處理每個詞並考慮前後文的順序。"
    },
    {
      "question": "RNN 面臨的一個主要技術障礙是什麼？",
      "options": [
        "注意力不足",
        "參數過多",
        "梯度消失 (gradient vanishing) 問題",
        "只能處理英文"
      ],
      "answer": 2,
      "description": "RNN 在反向傳播時容易出現梯度消失，使早期時間步的資訊難以影響模型，導致長距離依賴難以學習。"
    },
    {
      "question": "「詞嵌入」 (Word Embedding) 技術的主要目的是什麼？",
      "options": [
        "將文字轉換成有意義的、神經網路可以處理的數字向量",
        "計算一句話有多少個字",
        "讓 AI 玩文字接龍",
        "修正 AI 的幻覺"
      ],
      "answer": 0,
      "description": "詞嵌入會把詞語轉為連續的向量表示，讓語意相近的詞彼此距離更近，便於神經網路理解。"
    },
    {
      "question": "詞嵌入展現了什麼神奇的特性，例如「國王 - 男人 + 女人」會接近「皇后」？",
      "options": [
        "隨機性",
        "詞語間的向量運算關係",
        "只能處理皇室詞彙",
        "梯度下降"
      ],
      "answer": 1,
      "description": "詞嵌入位於多維語意空間中，使得詞語之間可以進行向量運算並保留語意關係。"
    },
    {
      "question": "將連續文字分割成「token」的過程稱為什麼？",
      "options": [
        "編碼 (Encoding)",
        "湧現 (Emergence)",
        "斷詞 (Tokenization)",
        "幻覺 (Hallucination)"
      ],
      "answer": 2,
      "description": "Tokenization 將文字切分成更小的單位，讓模型能以固定的片段進行處理與分析。"
    },
    {
      "question": "2017 年 Google 論文提出的、成為現代大語言模型核心的架構是什麼？",
      "options": [
        "RNN (遞迴神經網路)",
        "N-gram",
        "Transformer (變形金剛)",
        "MMLU"
      ],
      "answer": 2,
      "description": "Google 團隊在《Attention is All You Need》論文中提出 Transformer，使模型能以注意力機制取代傳統序列運算。"
    },
    {
      "question": "Transformer 裡的「自注意力機制」 (Self-Attention) 主要作用是什麼？",
      "options": [
        "讓模型隨機猜測",
        "讓每個詞決定該「注意」句子中的哪些其他詞",
        "強制模型一次只能看一個詞",
        "減少模型的參數"
      ],
      "answer": 1,
      "description": "自注意力機制讓每個詞按照上下文調整對其他詞的注意力，從而捕捉長距離依賴與語意關聯。"
    },
    {
      "question": "Transformer 如何在不依賴 RNN 序列處理的情況下理解詞的順序？",
      "options": [
        "它不需要理解順序",
        "使用「位置編碼」 (Positional Encoding)",
        "使用更多的 GPU",
        "依靠使用者的回饋"
      ],
      "answer": 1,
      "description": "Transformer 透過位置編碼為每個詞加入位置資訊，讓模型在並行處理時仍掌握詞序。"
    },
    {
      "question": "Transformer 經典架構中，負責理解輸入內容的模組稱為什麼？",
      "options": [
        "編碼器 (Encoder)",
        "解碼器 (Decoder)",
        "詞嵌入 (Word Embedding)",
        "注意力 (Attention)"
      ],
      "answer": 0,
      "description": "編碼器模組將輸入序列轉換為內部表示，提供後續解碼或其他任務使用。"
    },
    {
      "question": "Transformer 經典架構中，負責產生輸出序列的模組稱為什麼？",
      "options": [
        "編碼器 (Encoder)",
        "解碼器 (Decoder)",
        "N-gram",
        "MMLU"
      ],
      "answer": 1,
      "description": "解碼器根據編碼器輸出的語意表示逐步生成序列，產生所需的回答或翻譯。"
    },
    {
      "question": "「多頭注意力機制」 (Multi-Head Attention) 被比喻為什麼？",
      "options": [
        "只有一個老闆在看",
        "像金魚一樣的記憶力",
        "多線並行地從不同角度觀察語意，像好幾個記者",
        "一個詞一個詞慢慢看"
      ],
      "answer": 2,
      "description": "多頭注意力同時從多個角度觀察句子，彷彿多位記者協力採訪，彙整出更完整的語意。"
    },
    {
      "question": "什麼是「智慧湧現」 (Intelligence Emergence) 現象？",
      "options": [
        "模型在訓練一開始就展現所有能力",
        "模型規模達到某個臨界點後，突然展現出未經設計的複雜能力",
        "模型只會預測下一個詞",
        "模型產生幻覺"
      ],
      "answer": 1,
      "description": "智慧湧現指的是模型規模足夠大時，會自然展現原本未特別訓練的高階能力，例如推理或創作。"
    },
    {
      "question": "關於「智慧湧現」的原理，目前的科學共識是什麼？",
      "options": [
        "它是由詞嵌入引起的",
        "它是由 RNN 引起的",
        "科學家已經完全理解了",
        "目前沒有人知道確切的原理"
      ],
      "answer": 3,
      "description": "目前對於智慧湧現的機制仍未有定論，研究者正在積極探索其背後的原因。"
    },
    {
      "question": "大語言模型的「幻覺」 (Hallucination) 是指什麼？",
      "options": [
        "AI 看到了不存在的圖片",
        "AI 生成看似有道理，但實際上錯誤或虛構的內容",
        "AI 拒絕回答問題",
        "AI 運算速度變慢"
      ],
      "answer": 1,
      "description": "所謂幻覺是指模型生成的內容語法通順卻不符合事實，甚至完全虛構。"
    },
    {
      "question": "下列何者是 AI 產生幻覺的技術原因之一？",
      "options": [
        "AI 太聰明了",
        "AI 基於統計機率來決定下一個詞，而非真正「理解」",
        "AI 的訓練資料太過真實",
        "AI 的參數太少"
      ],
      "answer": 1,
      "description": "由於模型依靠統計機率選詞而非真正理解世界，缺乏可信資料時可能會自行編造內容。"
    },
    {
      "question": "哪種方法可以減少 AI 幻覺，就像「讓 AI 先查資料再回答」？",
      "options": [
        "使用 RNN",
        "讓 AI 讀八卦論壇",
        "讓 AI 先去查詢文件或資料庫 (RAG)",
        "讓 AI 過度自信"
      ],
      "answer": 2,
      "description": "檢索式增強生成 (RAG) 會在作答前參考外部資料，降低模型依靠模糊記憶時出錯的機率。"
    },
    {
      "question": "Meta 的 Llama 3 採用了何種「半開放」策略？",
      "options": [
        "完全閉源，僅供內部使用",
        "完全開源，沒有任何限制",
        "允許商用，但月活躍用戶超過7億的企業需額外申請授權",
        "只開源了模型架構，沒有開源權重"
      ],
      "answer": 2,
      "description": "Llama 3 採取半開放授權，允許大多數企業使用，但對超大規模平台提出額外申請條件。"
    },
    {
      "question": "與 Meta 相比，DeepSeek 的開源策略有何不同？",
      "options": [
        "更封閉，只提供 API",
        "更極致開放，連訓練程式碼和技術細節都釋出，並採用 MIT 等寬鬆條款",
        "完全相同，沒有區別",
        "只允許學術研究，不允許商用"
      ],
      "answer": 1,
      "description": "DeepSeek 選擇高度開源的策略，公開權重與訓練流程，並以寬鬆授權條款方便社群採用。"
    },
    {
      "question": "中國的一些 AI 公司（如 DeepSeek、阿里）傾向於採取開源策略的原因之一是什麼？",
      "options": [
        "因為他們不希望獲利",
        "為了快速建立國際影響力、搶佔話語權，並在技術封鎖時確保自主性",
        "因為他們的模型比較小",
        "因為美國公司強迫他們開源"
      ],
      "answer": 1,
      "description": "採用開源策略有助於快速建立全球影響力、吸引開發者參與，並在遭遇技術限制時維持自主性。"
    },
    {
      "question": "MMLU 是一個怎樣的評測基準？",
      "options": [
        "評測 AI 玩文字接龍的能力",
        "評測 AI 繪圖的能力",
        "涵蓋 57 個領域的大學及研究所層級專業知識選擇題",
        "小學到初中的科學知識推理測試"
      ],
      "answer": 2,
      "description": "MMLU 是一套涵蓋 57 個專業領域的評測，難度對應大學與研究所層級，用於評估模型的綜合專業知識與推理能力。 "
    },
    {
      "question": "ARC-AGI-2 基準測試的獨特之處在哪裡？",
      "options": [
        "題目非常簡單",
        "只測試數學能力",
        "AI 必須在沒有事先說明規則的情況下，從範例中推斷出規則",
        "全部都是是非題"
      ],
      "answer": 2,
      "description": "ARC-AGI-2 強調歸納推理，要求模型僅憑觀察範例自行猜測規則，再解決新的拼圖題。"
    },
    {
      "question": "哪一個評測基準專門用來測試 LLM 撰寫程式碼的能力？",
      "options": [
        "MMLU",
        "HumanEval",
        "ARC",
        "GSM8K"
      ],
      "answer": 1,
      "description": "HumanEval 是 OpenAI 提出的 Python 程式碼生成評測，透過自動單元測試驗證模型寫出的函式是否正確。"
    },
    {
      "question": "哪一個 LLM 排名榜單是透過用戶雙盲投票產生的，最能反映「實際使用體驗」？",
      "options": [
        "Chatbot Arena (LMSYS.org)",
        "Open LLM Leaderboard (Hugging Face)",
        "HELM (Stanford)",
        "MMLU 官方排名"
      ],
      "answer": 0,
      "description": "Chatbot Arena 是透過用戶實際對話並進行雙盲投票來排名的，因此最能反映模型的「實際使用體驗」。 "
    },
    {
      "question": "使用 AI 助手（如 ChatGPT）時，我們的對話內容通常會被如何處理？",
      "options": [
        "對話內容會立刻被刪除，不會被儲存",
        "對話內容會被收集和儲存，用於改進模型等目的",
        "只有中國的 AI 服務會收集數據",
        "只有美國的 AI 服務會收集數據"
      ],
      "answer": 1,
      "description": "多數服務提供者會在隱私政策中說明，對話資料可能被留存並作為改善模型或防止濫用的依據。"
    },
    {
      "question": "如果 DeepSeek 模型是開源的，為什麼使用它的服務仍可能有隱私風險？",
      "options": [
        "開源模型更危險",
        "隱私風險與誰「部署」服務並控制伺服器有關，而非模型本身",
        "DeepSeek 強制所有數據都必須送到中國",
        "開源模型無法加密"
      ],
      "answer": 1,
      "description": "即使模型是開源的，但數據隱私的風險取決於服務「部署」在哪裡，以及由誰來控制該伺服器。 "
    },
    {
      "question": "為了保護隱私，下列哪一項不是良好的使用 AI 助手習慣？",
      "options": [
        "避免分享個人敏感資訊",
        "定期清理對話歷史",
        "盡量分享商業機密，讓 AI 學習",
        "仔細閱讀服務條款和隱私政策"
      ],
      "answer": 2,
      "description": "良好做法包含不要上傳敏感資料並理解隱私政策，因此主動分享商業機密是錯誤的選擇。"
    },
    {
      "question": "哪一項現象被視為通往真正人工智慧的重要里程碑之一？",
      "options": [
        "智慧湧現",
        "N-gram",
        "幻覺",
        "評測基準"
      ],
      "answer": 0,
      "description": "智慧湧現顯示模型在規模擴張時會冒出新能力，被視為邁向更通用人工智慧的關鍵指標。"
    }
  ]