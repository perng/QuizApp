[
    {
      "question": "根據文本，語言模型 (Language Model) 最基本的核心任務是什麼？",
      "options": [
        "回答哲學問題",
        "理解人類情感",
        "預測下一個最可能出現的詞",
        "翻譯所有語言"
      ],
      "answer": 2,
      "description": "文本一開始就定義，語言模型的核心任務就是「預測下一個最可能出現的詞」。 "
    },
    {
      "question": "N-gram 模型最大的缺點是什麼？",
      "options": [
        "計算速度太快",
        "無法處理中文",
        "記憶力很差，無法處理長距離的詞語依賴",
        "需要神經網路"
      ],
      "answer": 2,
      "description": "N-gram 模型的「記憶力」很差，只能看到眼前的幾個字，無法處理像「小明...巧克力」這樣的長距離依賴。 "
    },
    {
      "question": "為什麼早期的神經網路無法分辨「我砍你」和「你砍我」？",
      "options": [
        "因為它們沒有足夠的參數",
        "因為它們處理時丟失了字詞的順序",
        "因為它們沒有使用詞嵌入",
        "因為它們是閉源的"
      ],
      "answer": 1,
      "description": "古典神經網路的輸入端沒有順序，傳入的值是加總起來的，因此「我砍你」和「你砍我」會被視為相同，丟失了順序資訊。 "
    },
    {
      "question": "遞迴神經網路 (RNN) 嘗試解決什麼問題？",
      "options": [
        "將詞語順序納入考慮",
        "讓模型變更大",
        "讓 AI 產生幻覺",
        "評估模型的好壞"
      ],
      "answer": 0,
      "description": "RNN 的設計就是為了將詞語的順序納入考慮，方法是讓神經元的輸出送回給自己，依序處理每個詞。 "
    },
    {
      "question": "文本提到 RNN 遇到的一個主要技術障礙是什麼？",
      "options": [
        "注意力不足",
        "參數過多",
        "梯度消失 (gradient vanishing) 問題",
        "只能處理英文"
      ],
      "answer": 2,
      "description": "文本提到 RNN 的一個大問題是「梯度消失」，這導致在處理長句子時，前面的資訊會在傳遞過程中逐漸消失。 "
    },
    {
      "question": "「詞嵌入」 (Word Embedding) 技術的主要目的是什麼？",
      "options": [
        "將文字轉換成有意義的、神經網路可以處理的數字向量",
        "計算一句話有多少個字",
        "讓 AI 玩文字接龍",
        "修正 AI 的幻覺"
      ],
      "answer": 0,
      "description": "詞嵌入技術將文字轉換成有意義的「意義向量」（一串連續的數值），這樣神經網路才能處理它們。"
    },
    {
      "question": "詞嵌入展現了什麼神奇的特性，例如「國王 - 男人 + 女人」會接近「皇后」？",
      "options": [
        "隨機性",
        "詞語間的向量運算關係",
        "只能處理皇室詞彙",
        "梯度下降"
      ],
      "answer": 1,
      "description": "詞嵌入將詞語放在一個多維空間中，使得詞語之間可以進行有意義的向量運算，例如「國王 - 男人 + 女人」會接近「皇后」。 "
    },
    {
      "question": "將連續文字分割成「token」的過程稱為什麼？",
      "options": [
        "編碼 (Encoding)",
        "湧現 (Emergence)",
        "斷詞 (Tokenization)",
        "幻覺 (Hallucination)"
      ],
      "answer": 2,
      "description": "文本明確定義，把連續文字分割成 \"token\" 的過程就叫做「斷詞 (tokenization)」。"
    },
    {
      "question": "2017 年 Google 論文提出的，成為現代大語言模型核心的架構是什麼？",
      "options": [
        "RNN (遞迴神經網路)",
        "N-gram",
        "Transformer (變形金剛)",
        "MMLU"
      ],
      "answer": 2,
      "description": "文本提到 2017 年 Google 的論文《Attention is All You Need》提出了 Transformer 架構，這是現代大語言模型的核心。 "
    },
    {
      "question": "Transformer 裡的「自注意力機制」 (Self-Attention) 主要作用是什麼？",
      "options": [
        "讓模型隨機猜測",
        "讓每個詞決定該「注意」句子中的哪些其他詞",
        "強制模型一次只能看一個詞",
        "減少模型的參數"
      ],
      "answer": 1,
      "description": "自注意力（Self-Attention）機制允許每個詞自行決定在句子中應該關注哪些其他詞，並動態調整關注的強度。"
    },
    {
      "question": "Transformer 如何在沒有 RNN 序列處理的情況下，還能理解詞的順序？",
      "options": [
        "它不需要理解順序",
        "使用「位置編碼」 (Positional Encoding)",
        "使用更多的 GPU",
        "依靠使用者的回饋"
      ],
      "answer": 1,
      "description": "Transformer 透過「位置編碼」 (Positional Encoding) 來解決順序問題，這是一種額外加入的數學向量，讓模型知道每個詞的位置。 "
    },
    {
      "question": "Transformer 經典架構中，負責「讀懂輸入」的模組稱為什麼？",
      "options": [
        "編碼器 (Encoder)",
        "解碼器 (Decoder)",
        "詞嵌入 (Word Embedding)",
        "注意力 (Attention)"
      ],
      "answer": 0,
      "description": "Transformer 架構分為兩部分，其中負責「讀懂輸入」並將其轉換為「理解向量」的模組是編碼器 (Encoder)。 "
    },
    {
      "question": "Transformer 經典架構中，負責「產出回應」的模組稱為什麼？",
      "options": [
        "編碼器 (Encoder)",
        "解碼器 (Decoder)",
        "N-gram",
        "MMLU"
      ],
      "answer": 1,
      "description": "Transformer 架構中，負責根據編碼器的理解來「生成新的文字」或「產出回應」的模組是解碼器 (Decoder)。 "
    },
    {
      "question": "「多頭注意力機制」 (Multi-Head Attention) 被比喻為什麼？",
      "options": [
        "只有一個老闆在看",
        "像金魚一樣的記憶力",
        "多線並行地從不同角度觀察語意，像好幾個記者",
        "一個詞一個詞慢慢看"
      ],
      "answer": 2,
      "description": "「多頭注意力機制」被比喻為好幾個記者從不同角度同時提問，以便彙整出更全面、更有深度的理解。"
    },
    {
      "question": "什麼是「智慧湧現」 (Intelligence Emergence) 現象？",
      "options": [
        "模型在訓練一開始就展現所有能力",
        "模型規模達到某個臨界點後，突然展現出未經設計的複雜能力",
        "模型只會預測下一個詞",
        "模型產生幻覺"
      ],
      "answer": 1,
      "description": "智慧湧現是指當模型規模和訓練數據達到某個「臨界點」後，突然冒出像推理、創作等未經原始設計的意外能力。 "
    },
    {
      "question": "關於「智慧湧現」的原理，目前的科學共識是什麼？",
      "options": [
        "它是由詞嵌入引起的",
        "它是由 RNN 引起的",
        "科學家已經完全理解了",
        "目前沒有人知道確切的原理"
      ],
      "answer": 3,
      "description": "文本明確提到，一個「壞消息」是目前科學家都不知道智慧湧現的確切原理是什麼。 "
    },
    {
      "question": "大語言模型的「幻覺」 (Hallucination) 是指什麼？",
      "options": [
        "AI 看到了不存在的圖片",
        "AI 生成看似有道理，但實際上錯誤或虛構的內容",
        "AI 拒絕回答問題",
        "AI 運算速度變慢"
      ],
      "answer": 1,
      "description": "文本定義 AI 幻覺為：生成看似有道理、語法通順，但實際上是錯誤或虛構的內容。"
    },
    {
      "question": "下列何者是 AI 產生幻覺的技術原因之一？",
      "options": [
        "AI 太聰明了",
        "AI 基於統計機率來決定下一個詞，而非真正「理解」",
        "AI 的訓練資料太過真實",
        "AI 的參數太少"
      ],
      "answer": 1,
      "description": "幻覺的原因之一是 AI 並非真正「理解」內容，而是根據統計機率預測下一個詞，這有時會導致它「編造」出看似合理但錯誤的答案。"
    },
    {
      "question": "文本中提到哪種方法可以減少 AI 幻覺，就像「讓 AI 查資料再回答」？",
      "options": [
        "使用 RNN",
        "讓 AI 讀八卦論壇",
        "讓 AI 先去查詢文件或資料庫 (RAG)",
        "讓 AI 過度自信"
      ],
      "answer": 2,
      "description": "減少幻覺的方法之一是讓 AI 在回答前先去查詢文件或資料庫（即 RAG），而不是完全依賴其內部記憶。"
    },
    {
      "question": "Meta 的 Llama 3 採用了何種「半開放」策略？",
      "options": [
        "完全閉源，僅供內部使用",
        "完全開源，沒有任何限制",
        "允許商用，但月活躍用戶超過7億的企業需額外申請授權",
        "只開源了模型架構，沒有開源權重"
      ],
      "answer": 2,
      "description": "Llama 採用「半開放」策略，雖然允許商用，但對月活躍用戶超過 7 億的大型企業設有額外的授權要求。 "
    },
    {
      "question": "與 Meta 相比，DeepSeek 的開源策略有何不同？",
      "options": [
        "更封閉，只提供 API",
        "更極致開放，連訓練程式碼和技術細節都釋出，並採用 MIT 等寬鬆條款",
        "完全相同，沒有區別",
        "只允許學術研究，不允許商用"
      ],
      "answer": 1,
      "description": "DeepSeek 採取了比 Meta 更極致的開放路線，不僅公開權重，還釋出了訓練程式碼和技術細節，並使用 MIT 等非常寬鬆的授權條款。"
    },
    {
      "question": "根據文本，為什麼中國的 AI 公司（如 DeepSeek、阿里）傾向於採取開源策略？",
      "options": [
        "因為他們不希望獲利",
        "為了快速建立國際影響力、搶佔話語權，並在技術封鎖時確保自主性",
        "因為他們的模型比較小",
        "因為美國公司強迫他們開源"
      ],
      "answer": 1,
      "description": "文本分析，中國企業採用開源策略是為了建立國際影響力、搶佔話語權、加速技術迭代，並在面對技術封鎖時確保自主性。"
    },
    {
      "question": "MMLU 是一個怎樣的評測基準？",
      "options": [
        "評測 AI 玩文字接龍的能力",
        "評測 AI 繪圖的能力",
        "涵蓋 57 個領域的大學及研究所層級專業知識選擇題",
        "小學到初中的科學知識推理測試"
      ],
      "answer": 2,
      "description": "MMLU 是一套涵蓋 57 個專業領域的評測，難度對應大學與研究所層級，用於評估模型的綜合專業知識與推理能力。 "
    },
    {
      "question": "ARC-AGI-2 基準測試的獨特之處在哪裡？",
      "options": [
        "題目非常簡單",
        "只測試數學能力",
        "AI 必須在沒有事先說明規則的情況下，從範例中推斷出規則",
        "全部都是是非題"
      ],
      "answer": 2,
      "description": "如圖 "
    },
    {
      "question": "哪一個評測基準專門用來測試 LLM 撰寫程式碼的能力？",
      "options": [
        "MMLU",
        "HumanEval",
        "ARC",
        "GSM8K"
      ],
      "answer": 1,
      "description": "文本明確指出，HumanEval 是 OpenAI 提出的，專門用來測試 LLM 撰寫 Python 程式碼能力的基準。 "
    },
    {
      "question": "哪一個 LLM 排名榜單是透過用戶雙盲投票產生的，最能反映「實際使用體驗」？",
      "options": [
        "Chatbot Arena (LMSYS.org)",
        "Open LLM Leaderboard (Hugging Face)",
        "HELM (Stanford)",
        "MMLU 官方排名"
      ],
      "answer": 0,
      "description": "Chatbot Arena 是透過用戶實際對話並進行雙盲投票來排名的，因此最能反映模型的「實際使用體驗」。 "
    },
    {
      "question": "根據文本，使用 AI 助手（如 ChatGPT）時，我們的對話內容會被如何處理？",
      "options": [
        "對話內容會立刻被刪除，不會被儲存",
        "對話內容會被收集和儲存，用於改進模型等目的",
        "只有中國的 AI 服務會收集數據",
        "只有美國的 AI 服務會收集數據"
      ],
      "answer": 1,
      "description": "文本指出，根據 OpenAI 等公司的隱私政策，用戶的對話內容會被收集和儲存，以用於改進模型性能和防止濫用。 "
    },
    {
      "question": "如果 DeepSeek 模型是開源的，為什麼使用它的服務仍可能有隱私風險？",
      "options": [
        "開源模型更危險",
        "隱私風險與誰「部署」服務並控制伺服器有關，而非模型本身",
        "DeepSeek 強制所有數據都必須送到中國",
        "開源模型無法加密"
      ],
      "answer": 1,
      "description": "即使模型是開源的，但數據隱私的風險取決於服務「部署」在哪裡，以及由誰來控制該伺服器。 "
    },
    {
      "question": "為了保護隱私，文本給出的「最佳實踐建議」不包含哪一項？",
      "options": [
        "避免分享個人敏感資訊",
        "定期清理對話歷史",
        "盡量分享商業機密，讓 AI 學習",
        "仔細閱讀服務條款和隱私政策"
      ],
      "answer": 2,
      "description": "文本明確建議「不要上傳機密文件或商業數據」，因此 (C) 是錯誤的做法。 "
    },
    {
      "question": "哪一項技術被認為是 AI 發展的初期階段，只是「通往真正人工智慧的重要里程碑」？",
      "options": [
        "智慧湧現",
        "N-gram",
        "幻覺",
        "評測基準"
      ],
      "answer": 0,
      "description": "文本在討論「智慧湧現」時總結道，這些「意外的驚喜」可能只是 AI 發展的初期階段，是通往真正人工智慧的重要里程碑。 "
    }
  ]