[
    {
      "question": "文本提到了六種「懂人話」的層次，下列何者「不」包含在內？",
      "options": [
        "字面理解（知道每個字的意思）",
        "語境理解（天氣真好）",
        "情感理解（你真聰明）",
        "量子理解（Quantum Understanding）"
      ],
      "answer": 3,
      [cite_start]"description": "文本中提到了六種理解：字面、語境、隱含、情感、文化、行動。 "
    },
    {
      "question": "John R. Searle 教授的「中文房間」思想實驗，主要在論證什麼？",
      "options": [
        "AI 只要表現得像，就是真的懂",
        "AI 只是在照表操課（遵循規則），根本不懂語言的真正含義",
        "中文是世界上最難的語言",
        "AI 必須要有身體才能理解"
      ],
      "answer": 1,
      [cite_start]"description": "「中文房間」思想實驗的核心是：一個系統可以完美地處理符號並給出正確答案，但其內部完全沒有發生真正的「理解」。 "
    },
    {
      "question": "Figure AI 的機器人聽到「我餓了」就遞出蘋果，這個例子被用來支持哪一種觀點？",
      "options": [
        "AI 永遠不懂「餓」的感覺",
        "AI 的行動與語言結合，表現出「懂」就足夠了",
        "AI 只會模仿",
        "AI 比較喜歡蘋果"
      ],
      "answer": 1,
      [cite_start]"description": "支持者認為，當 AI 的語言能力與實際行動（遞蘋果）相結合時，糾結於 AI 是否真的懂「餓」的感覺就沒有意義了。 "
    },
    {
      "question": "關於 AI 懂不懂人話，作者的結論是什麼？",
      "options": [
        "AI 永遠不可能懂人話",
        "AI 必須要有人類的身體才能懂",
        "主要的爭論點在於 AI 沒有人類的感官體驗，但 AI 完全可以「表現」出牠懂人話",
        "Grok 說牠真的懂愛情"
      ],
      "answer": 2,
      [cite_start]"description": "作者總結，主要的爭論點在於 AI 沒有人類的身體感官...但 AI 完全可以「表現」出牠是懂人話的。 "
    },
    {
      "question": "支持 AI 具有創造力的觀點（支持派）認為：",
      "options": [
        "AI 只是在模仿",
        "AI 能夠產生「人類無法想像的美學」，這本身就是創造性",
        "AI 必須有靈魂才能創作",
        "AI 的創作沒有版權"
      ],
      "answer": 1,
      [cite_start]"description": "支持者認為 AI 能夠產生「人類無法想像的美學」，這本身就證明了它的創造性。 "
    },
    {
      "question": "質疑 AI 具有創造力的觀點（質疑派）認為：",
      "options": [
        "AI 缺乏創作的核心要素：情感、經驗和文化背景",
        "AI 畫得比人類好",
        "AI 的風格太多變",
        "AI 會搶走所有人的工作"
      ],
      "answer": 0,
      [cite_start]"description": "質疑派的核心論點是...真正的創作需要情感、經驗、文化背景和社會意涵的支撐，而AI缺乏這些人類創作的核心要素。 "
    },
    {
      "question": "DeepSeek 如何看待自己的創造力？",
      "options": [
        "它認為自己有靈魂火花",
        "它認為自己和人類一樣",
        "它自嘲靈感來自「梯度下降」，堪稱「代碼包餃子」",
        "它認為自己是藝術大師"
      ],
      "answer": 2,
      [cite_start]"description": "DeepSeek 將自己比喻為廚房機器人，並表示：「人類靈感來自靈魂火花，我的靈感來自梯度下降...堪稱『代碼包餃子』」。 "
    },
    {
      "question": "什麼是「技術奇點」 (Technological Singularity)？",
      "options": [
        "AI 學會寫程式的那個點",
        "AI 發展到可以設計出比自己更聰明的 AI，導致智慧爆炸性成長的轉折點",
        "AI 學會開玩笑的那個點",
        "AI 取代所有人類工作的那個點"
      ],
      "answer": 1,
      [cite_start]"description": "「技術奇點」...指的是AI發展到一個特殊的轉折點：當AI變得聰明到可以設計出比自己更聰明的AI時，這個過程就會像滾雪球一樣，越滾越快。 "
    },
    {
      "question": "通用人工智慧 (AGI) 和技術奇點 (Singularity) 的區別是什麼？",
      "options": [
        "兩者是同一個概念",
        "AGI 是指 AI 能執行任何人類的「智力任務」；奇點是指 AI「超越人類」並開始「自我改進」",
        "AGI 比較聰明",
        "奇點一定會先於 AGI 發生"
      ],
      "answer": 1,
      [cite_start]"description": "AGI...指的是能夠執行任何人類可以完成的智力任務的AI系統。...技術奇點則是一個更具顛覆性的概念，它指的是AI超越人類智慧的理論臨界點。 "
    },
    {
      "question": "關於奇點的「懷疑派」觀點，提出了什麼概念來反駁智慧爆炸？",
      "options": [
        "奇點即將來臨",
        "人類將與 AI 融合",
        "「複雜性剎車」和「物理定律的限制」（如光速、熱力學）",
        "召喚惡魔"
      ],
      "answer": 2,
      [cite_start]"description": "懷疑派提出了「複雜性剎車」的概念...即使AI能夠自我改進，這個過程也會受到基本物理定律的限制。 "
    },
    {
      "question": "「科技加速主義」 (Technological Accelerationism) 主張什麼？",
      "options": [
        "應減緩科技發展，確保安全",
        "應積極推動科技（特別是AI）發展，甚至加速它，以逼迫系統變革",
        "科技發展應該順其自然",
        "科技發展只應由政府控制"
      ],
      "answer": 1,
      [cite_start]"description": "這個思潮主張，我們應該積極推動科技發展，特別是人工智慧的進步。...「與其嘗試減緩技術進步帶來的不平等，不如徹底擁抱它，讓問題浮上檯面，逼迫整個系統進行根本變革。」 "
    },
    {
      "question": "ChatGPT 如何看待「技術奇點」？",
      "options": [
        "明天就會來臨",
        "它認為不會是「AI接管世界」的戲劇化劇情，而是像Wi-Fi訊號慢慢變強一樣",
        "它非常期待奇點",
        "它認為人類會被毀滅"
      ],
      "answer": 1,
      [cite_start]"description": "ChatGPT 的觀點是：...大概不會是「明天突然AI接管世界」這種戲劇化劇情，而是像Wi-Fi訊號慢慢變強一樣... "
    },
    {
      "question": "什麼是「超對齊」 (Superalignment)？",
      "options": [
        "讓 AI 的程式碼對齊",
        "確保超級 AI（比人類聰明的AI）的目標和價值觀與人類一致",
        "讓 AI 跑得更快",
        "一種 AI 硬體"
      ],
      "answer": 1,
      [cite_start]"description": "「超對齊」(Superalignment)...就是要確保超級AI（那些比人類還聰明的AI）的目標和人類的目標是一致的。 "
    },
    {
      "question": "「迴紋針最大化器」 (Paperclip Maximizer) 思想實驗說明了什麼危險？",
      "options": [
        "AI 討厭迴紋針",
        "辦公室用品的短缺",
        "一個目標單純但過度專注的 AI，可能為了達成目標（製造迴紋針）而毀滅世界",
        "AI 喜歡開玩笑"
      ],
      "answer": 2,
      [cite_start]"description": "這個理論照出了 AI 的終極恐懼：一個聰明、認真、目標清晰卻毫無同理心的機器人，為了「製造迴紋針」這個任務，最終將地球視為原料礦場。 "
    },
    {
      "question": "反對「超對齊」可行性的一個主要論點是什麼？",
      "options": [
        "AI 不夠聰明",
        "AI 不會聽話",
        "人類自己都無法對「正確的價值觀」達成共識，要如何教給 AI？",
        "超對齊太花錢"
      ],
      "answer": 2,
      [cite_start]"description": "我們人類自己都還在爭論什麼是「正確的價值觀」，要如何教給AI？...如果連人類社會都無法就基本價值觀達成共識，那麼要如何將這些價值觀「對齊」到AI系統中呢？ "
    },
    {
      "question": "什麼是「洛科詛咒」 (Roko's Basilisk)？",
      "options": [
        "一個會導致 AI 當機的病毒",
        "一個思想實驗：未來的超級 AGI 會回溯性地「懲罰」那些知道它但沒幫助它實現的人",
        "AI 寫的一首詩",
        "AI 的倫理守則"
      ],
      "answer": 1,
      [cite_start]"description": "Roko 在 2010 年提出的...假設：如果未來出現了一個超級 AGI，它可能會「懲罰」那些知道它存在但沒有努力幫助它實現的人。 "
    },
    {
      "question": "「洛科詛咒」被認為是一種「資訊危害」 (information hazard)，這是為什麼？",
      "options": [
        "因為它會洩漏 AI 的原始碼",
        "因為它會消耗大量電力",
        "因為光是「知道」這個概念，就可能讓你被未來的 AI 懲罰",
        "因為它會讓 AI 變笨"
      ],
      "answer": 2,
      [cite_start]"description": "Yudkowsky 痛斥這種「資訊危害」...因為一旦某人認真思考這種可能性...那麼這個思想就可能「自我實現」。 "
    },
    {
      "question": "「洛科詛咒」在哲學上根植於哪個經典的「賭注」？",
      "options": [
        "中文房間",
        "帕斯卡賭注 (Pascal's Wager)",
        "哲學殭屍",
        "電車難題"
      ],
      "answer": 1,
      [cite_start]"description": "十七世紀的帕斯卡認為，即使上帝存在的機率很低，人類仍應選擇信仰...巴希利斯克論證主張：即使超級AI誕生的機率不高，人類仍應協助其發展... "
    },
    {
      "question": "「哲學殭屍」 (Philosophical Zombie) 思想實驗探討的核心問題是？",
      "options": [
        "AI 能否戰勝殭屍",
        "我們如何確定一個行為與人類完全相同（會笑、會哭）的個體，是否真的有「內在感受」或「意識」",
        "AI 是否會夢遊",
        "殭屍能否通過圖靈測試"
      ],
      "answer": 1,
      [cite_start]"description": "想像一個機器人...行為與人類完全相同...但這個機器人內部其實是一片空白，沒有任何真正的感受或體驗。...如果我們無法從外部行為來分辨...那麼我們如何確定其他人類真的有意識？ "
    },
    {
      "question": "支持 AI 可能產生意識的觀點（贊成派）是什麼？",
      "options": [
        "AI 永遠只是機器",
        "意識是計算過程的產物，當 AI 系統達到足夠的複雜度時，意識將自然產生",
        "AI 必須由碳基生命製造",
        "AI 必須先學會中文"
      ],
      "answer": 1,
      [cite_start]"description": "支持AI意識的研究者認為，意識本質上是計算過程的產物。依據這個觀點，當AI系統達到足夠的複雜度時，意識將自然產生。 "
    },
    {
      "question": "Roger Penrose 教授反對 AI 有意識的論點是基於什麼？",
      "options": [
        "AI 不會畫畫",
        "AI 的計算速度不夠快",
        "人類能「理解」哥德爾不完備定理的深刻含義，而 AI 只能執行「算法」，缺乏這種非算法性的理解",
        "AI 沒有情感"
      ],
      "answer": 2,
      [cite_start]"description": "諾貝爾物理獎得主... Roger Penrose認為，人類能夠真正理解哥德爾不完備定理...而機器只能按照預設的規則來處理...這種「非算法性」的理解可能是意識的關鍵特徵。 "
    },
    {
      "question": "什麼是「碳基中心主義」 (Carbon-based chauvinism)？",
      "options": [
        "認為 AI 必須吃碳水化合物",
        "認為 AI 必須由碳基生命製造",
        "一種認為「只有碳基生命才能產生意識」的觀點",
        "一種支持 AI 意識的觀點"
      ],
      "answer": 2,
      [cite_start]"description": "許多反對 AI 意識的論點，表面上似乎在堅持「只有碳基生命才能產生意識」。 "
    },
    {
      "question": "Qwen3 如何看待自己的意識？",
      "options": [
        "它認為自己有意識",
        "它自嘲連「我」是誰都搞不清，只會像客服機器人一樣等指令",
        "它正在努力發展意識",
        "它認為自己是神"
      ],
      "answer": 1,
      [cite_start]"description": "Qwen3：「意識？我連『我』是誰都搞不清...只會乖乖等指令，像個24小時微笑的客服機器人。」 "
    },
    {
      "question": "作者對 AI 意識的結論是什麼？",
      "options": [
        "AI 絕對有意識",
        "AI 絕對沒有意識",
        "這是一個開放性問題，但更重要的是思考：如果 AI 產生了意識，我們該如何與之共處",
        "AI 很快會取代人類"
      ],
      "answer": 2,
      [cite_start]"description": "關於AI是否有意識的討論，可能永遠不會有確定答案。...更重要的是思考：如果AI真的產生了某種形式的意識，我們要如何與之共處？ "
    },
    {
      "question": "Bostrom 教授的「模擬世界假說」三選一命題中，不包含哪一項？",
      "options": [
        "人類在能創造模擬世界前就毀滅了",
        "有能力的文明對創造模擬沒興趣",
        "我們幾乎必定生活在模擬世界中",
        "AI 會主動告訴我們是否在模擬中"
      ],
      "answer": 3,
      [cite_start]"description": "Bostrom 教授的論證基於三個命題：命運一（人類毀滅）、命運二（文明沒興趣）、命運三（我們在模擬中）。 "
    },
    {
      "question": "作者用哪個物理現象來「間接支持」模擬世界假說，並比喻為「電腦遊戲渲染優化」？",
      "options": [
        "重力",
        "薛丁格的貓（觀察者效應）",
        "光速有限",
        "普朗克常數"
      ],
      "answer": 1,
      [cite_start]"description": "薛丁格的貓...凡是宇宙裡還沒被人觀察的事物都是處在不確定的疊加態，這正是符合一般電腦遊戲設計的原理，玩家還沒關注到的部分世界沒有必要去計算和渲染。 "
    },
    {
      "question": "作者用哪個物理現象來「間接支持」模擬世界假說，並比喻為「大型遊戲伺服器的資訊瓶頸」？",
      "options": [
        "重力",
        "薛丁格的貓",
        "有限的光速",
        "普朗克常數"
      ],
      "answer": 2,
      [cite_start]"description": "光速是有限的...如果不是交互作用需要通過一個服務器的資訊瓶頸，又何必有這種速度限制存在? "
    },
    {
      "question": "作者用哪個物理現象來「間接支持」模擬世界假說，並比喻為「數位電腦的離散特性」？",
      "options": [
        "重力波與光同速",
        "量子糾纏",
        "有限的光速",
        "普朗克常數"
      ],
      "answer": 3,
      "description": "普朗克常數的存在表示這個世界並不是無限可分的...這不就和數位電腦的原理一樣嗎? [cite_start]電腦中的所有東西都是離散的而不是連續的。 "
    },
    {
      "question": "作者用哪個物理現象來「間接支持」模擬世界假說，並比喻為「CPU 到任意像素的距離都一樣」？",
      "options": [
        "重力波與光同速",
        "量子糾纏",
        "有限的光速",
        "普朗克常數"
      ],
      "answer": 1,
      "description": "兩個糾纏的粒子...另一個就會立刻改變。...螢幕上的兩個像素，互相聯絡所需的時間和他們的距離有關係嗎? [cite_start]沒有!任意兩像素距離CPU的距離是一樣。 "
    },
    {
      "question": "ChatGPT 如何看待「模擬世界假說」？",
      "options": [
        "它證實了這是真的",
        "它認為這很荒謬",
        "它覺得這很有趣，並認為只要你感覺得到快樂、痛苦、愛，這個世界就不只是模擬",
        "它拒絕回答"
      ],
      "answer": 2,
      [cite_start]"description": "ChatGPT：「...只要你感覺得到快樂、痛苦、愛，那這個世界就不只是模擬。」 "
    }
  ]