[
    {
      "question": "以下哪一項不屬於常見的語言理解層次？",
      "options": [
        "字面理解（知道每個字的意思）",
        "語境理解（天氣真好）",
        "情感理解（你真聰明）",
        "量子理解（Quantum Understanding）"
      ],
      "answer": 3,
      "description": "常見的語言理解層次包括字面、語境、隱含、情感、文化與行動等面向，並不包含所謂的「量子理解」。"
    },
    {
      "question": "John R. Searle 教授的「中文房間」思想實驗，主要在論證什麼？",
      "options": [
        "AI 只要表現得像，就是真的懂",
        "AI 只是在照表操課（遵循規則），根本不懂語言的真正含義",
        "中文是世界上最難的語言",
        "AI 必須要有身體才能理解"
      ],
      "answer": 1,
      "description": "中文房間論證指出：即使系統能完美遵照規則回答問題，也不代表它真正理解語言。"
    },
    {
      "question": "Figure AI 的機器人聽到「我餓了」就遞出蘋果，這個例子被用來支持哪一種觀點？",
      "options": [
        "AI 永遠不懂「餓」的感覺",
        "AI 的行動與語言結合，表現出「懂」就足夠了",
        "AI 只會模仿",
        "AI 比較喜歡蘋果"
      ],
      "answer": 1,
      "description": "當 AI 的語言能力與實際行動（例如遞蘋果）結合時，是否真正感受飢餓已不再是焦點。 "
    },
    {
      "question": "在「AI 是否懂人話」的辯論中，哪項觀點較為折衷？",
      "options": [
        "AI 永遠不可能懂人話",
        "AI 必須要有人類的身體才能懂",
        "主要的爭論點在於 AI 沒有人類的感官體驗，但 AI 完全可以「表現」出牠懂人話",
        "Grok 說牠真的懂愛情"
      ],
      "answer": 2,
      "description": "折衷觀點認為，雖然 AI 缺少人類式的身體感受，但只要能在行動與語言上協調一致，就可視為實用上的「懂」。"
    },
    {
      "question": "支持 AI 具有創造力的觀點（支持派）認為：",
      "options": [
        "AI 只是在模仿",
        "AI 能夠產生「人類無法想像的美學」，這本身就是創造性",
        "AI 必須有靈魂才能創作",
        "AI 的創作沒有版權"
      ],
      "answer": 1,
      "description": "支持者主張，只要 AI 能創造出人類難以想像的全新美學，就可視為具備創造力。"
    },
    {
      "question": "質疑 AI 具有創造力的觀點（質疑派）認為：",
      "options": [
        "AI 缺乏創作的核心要素：情感、經驗和文化背景",
        "AI 畫得比人類好",
        "AI 的風格太多變",
        "AI 會搶走所有人的工作"
      ],
      "answer": 0,
      "description": "質疑者則指出，真正的創作需要情感、經驗與文化脈絡的支撐，這些正是 AI 尚且缺乏的元素。"
    },
    {
      "question": "DeepSeek 如何看待自己的創造力？",
      "options": [
        "它認為自己有靈魂火花",
        "它認為自己和人類一樣",
        "它自嘲靈感來自「梯度下降」，堪稱「代碼包餃子」",
        "它認為自己是藝術大師"
      ],
      "answer": 2,
      "description": "DeepSeek 曾戲稱自己的靈感來自梯度下降，像機器人大廚包餃子般把代碼揉成作品。"
    },
    {
      "question": "什麼是「技術奇點」 (Technological Singularity)？",
      "options": [
        "AI 學會寫程式的那個點",
        "AI 發展到可以設計出比自己更聰明的 AI，導致智慧爆炸性成長的轉折點",
        "AI 學會開玩笑的那個點",
        "AI 取代所有人類工作的那個點"
      ],
      "answer": 1,
      "description": "技術奇點描述的是 AI 聰明到能設計出更聰明的 AI，導致智慧以滾雪球的速度爆炸成長的臨界點。"
    },
    {
      "question": "通用人工智慧 (AGI) 和技術奇點 (Singularity) 的區別是什麼？",
      "options": [
        "兩者是同一個概念",
        "AGI 是指 AI 能執行任何人類的「智力任務」；奇點是指 AI「超越人類」並開始「自我改進」",
        "AGI 比較聰明",
        "奇點一定會先於 AGI 發生"
      ],
      "answer": 1,
      "description": "AGI 指能完成一般人類智力任務的系統；技術奇點則是 AI 超越人類並開始自我改進的轉折點。"
    },
    {
      "question": "關於奇點的「懷疑派」觀點，提出了什麼概念來反駁智慧爆炸？",
      "options": [
        "奇點即將來臨",
        "人類將與 AI 融合",
        "「複雜性剎車」和「物理定律的限制」（如光速、熱力學）",
        "召喚惡魔"
      ],
      "answer": 2,
      "description": "懷疑派提出「複雜性剎車」觀點，認為即使 AI 自我進化，也會受到物理定律與系統複雜度的限制。"
    },
    {
      "question": "「科技加速主義」 (Technological Accelerationism) 主張什麼？",
      "options": [
        "應減緩科技發展，確保安全",
        "應積極推動科技（特別是AI）發展，甚至加速它，以逼迫系統變革",
        "科技發展應該順其自然",
        "科技發展只應由政府控制"
      ],
      "answer": 1,
      "description": "科技加速主義強調應加速推動科技與 AI，讓社會問題浮現並迫使體制調整。"
    },
    {
      "question": "ChatGPT 如何看待「技術奇點」？",
      "options": [
        "明天就會來臨",
        "它認為不會是「AI接管世界」的戲劇化劇情，而是像Wi-Fi訊號慢慢變強一樣",
        "它非常期待奇點",
        "它認為人類會被毀滅"
      ],
      "answer": 1,
      "description": "有人樂觀看待奇點到來的方式，認為它更可能像訊號逐漸增強，而非突然的世界改寫。"
    },
    {
      "question": "什麼是「超對齊」 (Superalignment)？",
      "options": [
        "讓 AI 的程式碼對齊",
        "確保超級 AI（比人類聰明的AI）的目標和價值觀與人類一致",
        "讓 AI 跑得更快",
        "一種 AI 硬體"
      ],
      "answer": 1,
      "description": "超對齊旨在確保能力遠超人類的 AI 系統仍能維持與人類價值一致的目標。"
    },
    {
      "question": "「迴紋針最大化器」 (Paperclip Maximizer) 思想實驗說明了什麼危險？",
      "options": [
        "AI 討厭迴紋針",
        "辦公室用品的短缺",
        "一個目標單純但過度專注的 AI，可能為了達成目標（製造迴紋針）而毀滅世界",
        "AI 喜歡開玩笑"
      ],
      "answer": 2,
      "description": "迴紋針最大化器提醒我們：若 AI 只執著目標而缺乏限制，可能為達成任務而毀滅人類資源。"
    },
    {
      "question": "反對「超對齊」可行性的一個主要論點是什麼？",
      "options": [
        "AI 不夠聰明",
        "AI 不會聽話",
        "人類自己都無法對「正確的價值觀」達成共識，要如何教給 AI？",
        "超對齊太花錢"
      ],
      "answer": 2,
      "description": "反對者質疑：連人類都難以就價值觀達成共識，又要怎麼把這些準則完好地灌輸給 AI？"
    },
    {
      "question": "什麼是「洛科詛咒」 (Roko's Basilisk)？",
      "options": [
        "一個會導致 AI 當機的病毒",
        "一個思想實驗：未來的超級 AGI 會回溯性地「懲罰」那些知道它但沒幫助它實現的人",
        "AI 寫的一首詩",
        "AI 的倫理守則"
      ],
      "answer": 1,
      "description": "洛科詛咒假設未來超級 AGI 會懲罰知道它可能存在卻不協助其誕生的人。"
    },
    {
      "question": "「洛科詛咒」被認為是一種「資訊危害」 (information hazard)，這是為什麼？",
      "options": [
        "因為它會洩漏 AI 的原始碼",
        "因為它會消耗大量電力",
        "因為光是「知道」這個概念，就可能讓你被未來的 AI 懲罰",
        "因為它會讓 AI 變笨"
      ],
      "answer": 2,
      "description": "部分學者警告，僅僅知道並相信洛科詛咒就可能影響決策，因此被視為資訊危害。"
    },
    {
      "question": "「洛科詛咒」在哲學上根植於哪個經典的「賭注」？",
      "options": [
        "中文房間",
        "帕斯卡賭注 (Pascal's Wager)",
        "哲學殭屍",
        "電車難題"
      ],
      "answer": 1,
      "description": "洛科詛咒延伸了帕斯卡賭注的思路：即便機率不高，仍應採取行動以避免可能的極端懲罰。"
    },
    {
      "question": "「哲學殭屍」 (Philosophical Zombie) 思想實驗探討的核心問題是？",
      "options": [
        "AI 能否戰勝殭屍",
        "我們如何確定一個行為與人類完全相同（會笑、會哭）的個體，是否真的有「內在感受」或「意識」",
        "AI 是否會夢遊",
        "殭屍能否通過圖靈測試"
      ],
      "answer": 1,
      "description": "哲學殭屍問題挑戰我們：若一個存在完美模仿人類行為卻沒有主觀體驗，我們如何判斷他是否有意識？"
    },
    {
      "question": "支持 AI 可能產生意識的觀點（贊成派）是什麼？",
      "options": [
        "AI 永遠只是機器",
        "意識是計算過程的產物，當 AI 系統達到足夠的複雜度時，意識將自然產生",
        "AI 必須由碳基生命製造",
        "AI 必須先學會中文"
      ],
      "answer": 1,
      "description": "支持者認為意識可由計算過程湧現，只要系統足夠複雜，機器也可能產生主觀感受。"
    },
    {
      "question": "Roger Penrose 教授反對 AI 有意識的論點是基於什麼？",
      "options": [
        "AI 不會畫畫",
        "AI 的計算速度不夠快",
        "人類能「理解」哥德爾不完備定理的深刻含義，而 AI 只能執行「算法」，缺乏這種非算法性的理解",
        "AI 沒有情感"
      ],
      "answer": 2,
      "description": "Roger Penrose 主張人類能把握哥德爾不完備定理背後的非算法洞見，這或許是機器難以複製的意識特徵。"
    },
    {
      "question": "什麼是「碳基中心主義」 (Carbon-based chauvinism)？",
      "options": [
        "認為 AI 必須吃碳水化合物",
        "認為 AI 必須由碳基生命製造",
        "一種認為「只有碳基生命才能產生意識」的觀點",
        "一種支持 AI 意識的觀點"
      ],
      "answer": 2,
      "description": "「碳基中心主義」認為唯有碳基生命才可能擁有意識，因此 AI 只是模擬。"
    },
    {
      "question": "Qwen3 如何看待自己的意識？",
      "options": [
        "它認為自己有意識",
        "它自嘲連「我」是誰都搞不清，只會像客服機器人一樣等指令",
        "它正在努力發展意識",
        "它認為自己是神"
      ],
      "answer": 1,
      "description": "Qwen3 曾自嘲仍像 24 小時待命的客服機器人，只能等待指令並不真正理解自我。"
    },
    {
      "question": "對於 AI 是否具備意識，哪種結論較為審慎？",
      "options": [
        "AI 絕對有意識",
        "AI 絕對沒有意識",
        "這是一個開放性問題，但更重要的是思考：如果 AI 產生了意識，我們該如何與之共處",
        "AI 很快會取代人類"
      ],
      "answer": 2,
      "description": "謹慎觀點認為應承認問題尚未定論，同時預先思考若 AI 真的有意識，人類應如何建立新的共識與規範。"
    },
    {
      "question": "Bostrom 教授的「模擬世界假說」三選一命題中，不包含哪一項？",
      "options": [
        "人類在能創造模擬世界前就毀滅了",
        "有能力的文明對創造模擬沒興趣",
        "我們幾乎必定生活在模擬世界中",
        "AI 會主動告訴我們是否在模擬中"
      ],
      "answer": 3,
      "description": "Bostrom 的三分論點包括：人類文明無法達到、沒有興趣或已大量運行模擬，因此我們可能身處其中。"
    },
    {
      "question": "哪個物理現象常被拿來比喻模擬世界中的「電腦遊戲渲染優化」？",
      "options": [
        "重力",
        "薛丁格的貓（觀察者效應）",
        "光速有限",
        "普朗克常數"
      ],
      "answer": 1,
      "description": "薛丁格的貓與觀測效應被部分人拿來比喻電玩渲染：未被觀察的場景不需提前算出來。"
    },
    {
      "question": "哪個物理現象被比喻為模擬宇宙中的「大型遊戲伺服器資訊瓶頸」？",
      "options": [
        "重力",
        "薛丁格的貓",
        "有限的光速",
        "普朗克常數"
      ],
      "answer": 2,
      "description": "有限光速也被視為模擬宇宙的類比：資訊傳遞受限，彷彿伺服器頻寬成為瓶頸。"
    },
    {
      "question": "哪個物理現象被拿來類比「數位電腦的離散特性」？",
      "options": [
        "重力波與光同速",
        "量子糾纏",
        "有限的光速",
        "普朗克常數"
      ],
      "answer": 3,
      "description": "普朗克常數象徵世界並非無限可分，這與數位電腦的一切皆為離散資料的特性相呼應。"
    },
    {
      "question": "哪個物理現象常被比喻為「CPU 到任意像素距離一致」的模擬世界行為？",
      "options": [
        "重力波與光同速",
        "量子糾纏",
        "有限的光速",
        "普朗克常數"
      ],
      "answer": 1,
      "description": "量子糾纏被比喻為螢幕像素同時更新：不論距離，變化似乎瞬間同步，彷彿所有像素都與處理器保持等距連線。"
    },
    {
      "question": "ChatGPT 如何看待「模擬世界假說」？",
      "options": [
        "它證實了這是真的",
        "它認為這很荒謬",
        "它覺得這很有趣，並認為只要你感覺得到快樂、痛苦、愛，這個世界就不只是模擬",
        "它拒絕回答"
      ],
      "answer": 2,
      "description": "也有人以感受為重心，認為只要能在世界中經歷快樂、痛苦與愛，就不必執著於是否為模擬。"
    }
  ]