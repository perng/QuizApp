[
    {
      "question": "圖靈測試 (Turing Test) 的目的為何？",
      "options": [
        "電腦的計算速度",
        "機器是否擁有人類智慧",
        "簡訊詐騙犯的真實身份",
        "AI 繪圖的精準度"
      ],
      "answer": 1,
      "description": "圖靈測試透過人與機器的文字對話，觀察人類是否能辨認出對方是機器，以評估機器是否展現出類似人類的智慧。"
    },
    {
      "question": "AI 的「學習能力」主要仰賴哪種方式？",
      "options": [
        "像人類一樣理解抽象概念",
        "透過觀察大量的例子来找出規律",
        "透過背誦規則書來學習",
        "透過與人類聊天来學習"
      ],
      "answer": 1,
      "description": "現代 AI 透過大量資料找出模式與規律，因此能在新情況下進行推論或預測。"
    },
    {
      "question": "AI 的模式識別能力可能出現的局限是？",
      "options": [
        "AI 無法分辨貓和狗",
        "AI 可能找出「穿藍色襪子，股市就會上漲」這種無實際意義的關聯",
        "AI 只能在特定領域內靈活運用",
        "AI 下棋時不知道自己在玩遊戲"
      ],
      "answer": 1,
      "description": "AI 會在資料中搜尋關聯，但不一定懂得判斷是否有實際意義，因此可能誤判巧合為真實規律。"
    },
    {
      "question": "關於「生成式 AI」和「傳統 AI」的差別，下列敘述何者錯誤？",
      "options": [
        "傳統 AI 傾向給出明確答案，生成式 AI 則是創造全新內容",
        "傳統 AI 學習「分類」和「預測」，生成式 AI 學習「創造」",
        "傳統 AI 的結果通常是固定的，生成式 AI 的結果每次可能不一樣",
        "傳統 AI 應用於繪畫創作，生成式 AI 應用於垃圾郵件過濾"
      ],
      "answer": 3,
      "description": "傳統 AI 多用於分類與預測任務，如垃圾郵件過濾；生成式 AI 則擅長產生文字、圖像等新內容，因此 (D) 描述與實際應用相反。"
    },
    {
      "question": "在 GPT 這個縮寫裡，字母 \"G\" 代表什麼？",
      "options": ["Google", "Generative (生成式)", "General (通用)", "Good (好的)"],
      "answer": 1,
      "description": "GPT 代表 Generative Pre-trained Transformer，其中 \"Generative\" 指的是模型能生成新的內容。"
    },
    {
      "question": "下列哪一項不屬於人工智慧的範例？",
      "options": [
        "一個能觀察觀影習慣並推薦電影的系統",
        "機器學習 (Machine Learning)",
        "一個只會按設定類型（如愛情片）列出清單的系統",
        "大語言模型 (Large Language Model)"
      ],
      "answer": 2,
      "description": "若系統只依照固定的條件輸出清單，沒有學習或推理能力，就不被視為人工智慧。"
    },
    {
      "question": "機器學習 (Machine Learning) 如何運作？",
      "options": [
        "告訴電腦所有明確的規則",
        "讓電腦從資料中學習規律，並用規律做決策",
        "讓電腦背誦「騎車步驟123」",
        "機器學習是達成 AI 的唯一方法"
      ],
      "answer": 1,
      "description": "機器學習讓模型從資料中歸納規則，再應用於新的案例做出預測或決策。"
    },
    {
      "question": "哪一種機器學習方式需要提供輸入與對應的正確標籤？",
      "options": [
        "監督式學習 (Supervised Learning)",
        "非監督式學習 (Unsupervised Learning)",
        "強化學習 (Reinforcement Learning)",
        "自監督學習 (Self-supervised Learning)"
      ],
      "answer": 0,
      "description": "監督式學習使用成對的輸入與標籤資料，讓模型學會將輸入對應到正確答案。"
    },
    {
      "question": "哪一種機器學習方式能在沒有資料標籤的情況下找出隱藏的規律？",
      "options": [
        "監督式學習 (Supervised Learning)",
        "非監督式學習 (Unsupervised Learning)",
        "強化學習 (Reinforcement Learning)",
        "自監督學習 (Self-supervised Learning)"
      ],
      "answer": 1,
      "description": "非監督式學習依靠未標記的資料，透過聚類或降維等方法找出資料中的結構。"
    },
    {
      "question": "哪一種機器學習方式會讓模型自己設計任務，例如遮住句子部分再預測缺漏的詞？",
      "options": [
        "監督式學習 (Supervised Learning)",
        "非監督式學習 (Unsupervised Learning)",
        "強化學習 (Reinforcement Learning)",
        "自監督學習 (Self-supervised Learning)"
      ],
      "answer": 3,
      "description": "自監督學習會從原始資料中製造訓練目標，例如遮住部分內容再預測，以建立模型的理解能力。"
    },
    {
      "question": "在生物神經元結構中，負責接收來自其他神經元訊息的部分是？",
      "options": [
        "樹突 (dendrites)",
        "神經元細胞體 (neuron cell body)",
        "軸突 (axon)",
        "權重 (weights)"
      ],
      "answer": 0,
      "description": "樹突是神經元用來接收其他神經元訊號的結構。"
    },
    {
      "question": "在人工神經網路中，參數主要來自哪兩個部分？",
      "options": [
        "輸入層與輸出層",
        "權重 (weights) 和偏差值 (bias)",
        "CPU 與 GPU",
        "卷積層與池化層"
      ],
      "answer": 1,
      "description": "神經網路的可調整參數主要包含連結的權重與各節點的偏差值。"
    },
    {
      "question": "在訓練神經網路時，用來衡量模型預測與真實答案差距的機制稱為什麼？",
      "options": [
        "正向傳遞 (Forward Propagation)",
        "損失函數 (Loss Function)",
        "反向傳播 (Back Propagation)",
        "梯度下降 (Gradient Descent)"
      ],
      "answer": 1,
      "description": "損失函數會計算模型輸出與目標值之間的差距，協助調整模型。"
    },
    {
      "question": "在神經網路訓練中，從目前的損失值反推並調整權重，使損失逐步下降的過程稱為？",
      "options": [
        "梯度下降 (Gradient Descent)",
        "過擬合 (Overfitting)",
        "閒置神經元 (Idle neuron)",
        "正向傳遞 (Forward Propagation)"
      ],
      "answer": 0,
      "description": "梯度下降沿著損失函數下降最快的方向調整參數，以降低誤差。"
    },
    {
      "question": "如果模型記住訓練資料的細節，却無法應對新情況，這種現象稱為什麼？",
      "options": [
        "欠擬合 (Underfitting)",
        "過擬合 (Overfitting)",
        "梯度消失 (Gradient Vanishing)",
        "反向傳播 (Back Propagation)"
      ],
      "answer": 1,
      "description": "過擬合代表模型在訓練資料上表現很好，但缺乏泛化能力。"
    },
    {
      "question": "如果模型的參數太少導致學不到足夠資訊，這種現象稱為什麼？",
      "options": [
        "欠擬合 (Underfitting)",
        "過擬合 (Overfitting)",
        "梯度爆炸 (Gradient Explosion)",
        "交叉驗證 (Cross-validation)"
      ],
      "answer": 0,
      "description": "欠擬合表示模型複雜度不足，無法充分描述資料的特徵。"
    },
    {
      "question": "下列哪一項不是常見的防止過擬合方法？",
      "options": [
        "正則化 (Regularization)",
        "早停法 (Early stopping)",
        "增加模型複雜度（增加參數量）",
        "資料擴增 (Data augmentation)"
      ],
      "answer": 2,
      "description": "為避免過擬合會採用正則化、早停或資料擴增等技巧；增加模型複雜度反而更易過擬合。"
    },
    {
      "question": "卷積神經網路 (CNN) 特別擅長處理哪一類型的資料？",
      "options": [
        "具有空間結構的資料（如圖片）",
        "純文字資料",
        "聲音訊號",
        "股票市場數據"
      ],
      "answer": 0,
      "description": "CNN 善於捕捉影像等具有空間結構的資料中的局部特徵。"
    },
    {
      "question": "在 CNN 中，負責以不同濾鏡掃描影像並偵測特定圖案的層級是？",
      "options": [
        "池化層 (Pooling Layer)",
        "卷積層 (Convolutional Layer)",
        "隱藏層 (Hidden Layer)",
        "輸出層 (Output Layer)"
      ],
      "answer": 1,
      "description": "卷積層透過各種卷積核偵測邊緣、角點等局部特徵。"
    },
    {
      "question": "在 CNN 中，負責縮減特徵圖並保留重點資訊的層級是？",
      "options": [
        "池化層 (Pooling Layer)",
        "卷積層 (Convolutional Layer)",
        "輸入層 (Input Layer)",
        "全連接神經網路 (Fully Connected NN)"
      ],
      "answer": 0,
      "description": "池化層會縮小特徵圖大小，保留重要資訊並降低計算量。"
    },
    {
      "question": "深度學習 (Deep Learning) 相較於傳統機器學習最大的優勢之一是什麼？",
      "options": [
        "只需要很少的訓練資料",
        "訓練速度非常快",
        "能夠自動學習特徵，不需要人工進行「特徵工程」",
        "完全不會有「過擬合」的問題"
      ],
      "answer": 2,
      "description": "深度學習能直接從資料中自動找出有效特徵，減少人工設計特徵的需求。"
    },
    {
      "question": "2015 年 ResNet 引入的「跳層連接」主要解決了哪項訓練問題？",
      "options": [
        "梯度消失 (Gradient Vanishing)",
        "資料量不足",
        "計算能力不夠",
        "過擬合 (Overfitting)"
      ],
      "answer": 0,
      "description": "跳層連接讓訊號可以跨層流動，減輕深度模型中的梯度消失問題。"
    },
    {
      "question": "生成對抗網路 (GAN) 是由哪兩個模型互相較勁組成的？",
      "options": [
        "卷積層與池化層",
        "生成器 (Generator) 與判別器 (Discriminator)",
        "監督式學習與非監督式學習",
        "智慧代理與環境"
      ],
      "answer": 1,
      "description": "GAN 包含一個產生資料的生成器與一個辨識真假的判別器，兩者彼此競爭共同進步。"
    },
    {
      "question": "在 GAN 中，哪個組件負責產生逼真的資料樣本？",
      "options": [
        "判別器 (Discriminator)，負責鑑定真假",
        "生成器 (Generator)，負責製造逼真的仿作",
        "損失函數 (Loss Function)，負責評估錯誤",
        "智慧代理 (Intelligent Agent)，負責與環境互動"
      ],
      "answer": 1,
      "description": "生成器的目標是產生看起來與真實資料相似的樣本，讓判別器難以分辨。"
    },
    {
      "question": "被濫用而引發深度偽造 (Deepfake) 擔憂的 AI 技術是？",
      "options": [
        "卷積神經網路 (CNN)",
        "強化學習 (Reinforcement Learning)",
        "對抗式學習 (Adversarial Learning) / GAN",
        "監督式學習 (Supervised Learning)"
      ],
      "answer": 2,
      "description": "Deepfake 多利用對抗式學習架構產生逼真的語音與影像，因此需要留意其濫用風險。"
    },
    {
      "question": "哪一種機器學習方法會在沒有標註資料的情況下，透過試錯與獎勵來學習？",
      "options": [
        "監督式學習 (Supervised Learning)",
        "非監督式學習 (Unsupervised Learning)",
        "強化學習 (Reinforcement Learning)",
        "自監督學習 (Self-supervised Learning)"
      ],
      "answer": 2,
      "description": "強化學習的智慧體透過與環境互動並根據獎勵訊號更新策略。"
    },
    {
      "question": "在強化學習的核心元素中，描述系統當前情況的部分屬於哪一個？",
      "options": [
        "智慧代理 (Intelligent Agent)",
        "環境 (Environment)",
        "狀態 (State)",
        "動作 (Action)"
      ],
      "answer": 2,
      "description": "狀態 (State) 用來描述智慧體所處的環境資訊，例如資源數量或位置。"
    },
    {
      "question": "在強化學習中，智慧體面臨探索新策略與利用已知策略的取捨被稱為什麼？",
      "options": [
        "探索-利用困境 (Exploration-Exploitation Dilemma)",
        "梯度消失問題 (Gradient Vanishing Problem)",
        "過擬合 (Overfitting)",
        "獎勵稀疏性 (Reward Rarity)"
      ],
      "answer": 0,
      "description": "探索-利用困境描述智慧體在嘗試新方法與使用既有高獎勵策略之間需要平衡的難題。"
    },
    {
      "question": "像 ChatGPT、Google Gemini 等現代系統目前被歸類為哪一種類型的 AI？",
      "options": [
        "通用人工智慧 (AGI)",
        "狹義人工智慧 (Narrow AI)",
        "生物神經網路 (Biological Neural Network)",
        "偽畫 AI (Forgery AI)"
      ],
      "answer": 1,
      "description": "即使功能強大，這些系統仍專注於特定任務，因此被視為狹義 AI。"
    },
    {
      "question": "通用人工智慧 (AGI) 與目前常見的 AI 最大的差異是？",
      "options": [
        "AGI 計算速度更快",
        "AGI 能畫出更逼真的圖片",
        "AGI 具有像人類一樣多面向的智慧，能真正理解世界並自主學習",
        "AGI 只需要更少的電力"
      ],
      "answer": 2,
      "description": "AGI 指能像人類一樣理解多種情境、具備通用智慧並能自主學習的系統。"
    },
    {
      "question": "誰被視為現代電腦與人工智慧的奠基者？",
      "options": [
        "圖靈 (Alan Turing)",
        "伊恩·古德費洛 (Ian Goodfellow)",
        "黃仁勳 (Jensen Huang)",
        "漢·凡·米格倫 (Han van Meegeren)"
      ],
      "answer": 0,
      "description": "艾倫·圖靈提出的理論為現代電腦科學與人工智慧奠定了基礎。"
    },
    {
      "question": "AI 的四個重要特質包含學習能力、模式識別、決策能力以及？",
      "options": [
        "適應能力 (Adaptation)",
        "創造能力 (Creativity)",
        "情感能力 (Emotion)",
        "社交能力 (Socialization)"
      ],
      "answer": 0,
      "description": "適應能力讓 AI 能根據環境變化調整行為，是智慧體的重要特質之一。"
    },
    {
      "question": "機器學習是 AI 的一個分支，而什麼又是機器學習的一個分支？",
      "options": [
        "神經網路 (Neural Network)",
        "深度偽造 (Deepfake)",
        "特徵工程 (Feature Engineering)",
        "卷積核 (Convolution Kernel)"
      ],
      "answer": 0,
      "description": "神經網路屬於機器學習中的一類模型，模仿生物神經系統的結構。"
    },
    {
      "question": "在神經網路訓練中，根據錯誤訊號反向調整權重的過程稱為？",
      "options": [
        "反向傳播 (Back Propagation)",
        "正向傳遞 (Forward Propagation)",
        "損失函數 (Loss Function)",
        "模式識別 (Pattern Recognition)"
      ],
      "answer": 0,
      "description": "反向傳播會沿著網路結構將誤差傳回前層，逐步更新權重。"
    },
    {
      "question": "在 CNN 中，負責偵測特定圖案的小矩陣稱為什麼？",
      "options": [
        "卷積核 (Convolution Kernel)",
        "池化層 (Pooling Layer)",
        "偏差值 (Bias)",
        "樹突 (Dendrite)"
      ],
      "answer": 0,
      "description": "卷積核是小尺寸的濾鏡，用來掃描影像並找出特定特徵。"
    },
    {
      "question": "在 CNN 的池化層中，最常用的方式是？",
      "options": [
        "最大池化 (Max Pooling)",
        "平均池化 (Average Pooling)",
        "最小池化 (Min Pooling)",
        "隨機池化 (Random Pooling)"
      ],
      "answer": 0,
      "description": "最大池化會在每個區塊選出最大值，既能保留顯著特徵又能降低維度。"
    },
    {
      "question": "神經網路層數過多時，梯度逐漸趨近零的現象稱為？",
      "options": [
        "梯度消失 (Gradient Vanishing)",
        "梯度爆炸 (Gradient Explosion)",
        "過擬合 (Overfitting)",
        "欠擬M合 (Underfitting)"
      ],
      "answer": 0,
      "description": "梯度消失會讓早期層的權重難以更新，使深度網路難以訓練。"
    },
    {
      "question": "「生成對抗網路」 (GAN) 的概念是由誰提出的？",
      "options": [
        "Ian Goodfellow",
        "Alan Turing",
        "Han van Meegeren",
        "Geoffrey Hinton"
      ],
      "answer": 0,
      "description": "Ian Goodfellow 於 2014 年首次提出生成對抗網路的概念。"
    },
    {
      "question": "在強化學習中，負責採取行動並學習策略的實體稱為？",
      "options": [
        "智慧代理 (Intelligent Agent)",
        "環境 (Environment)",
        "判別器 (Discriminator)",
        "生成器 (Generator)"
      ],
      "answer": 0,
      "description": "智慧代理會根據觀察到的狀態選擇動作並更新策略。"
    },
    {
      "question": "在強化學習中，將經驗存入記憶庫並隨機抽樣學習的技巧稱為？",
      "options": [
        "經驗回放 (Experience Replay)",
        "自監督學習 (Self-supervised Learning)",
        "反向傳播 (Back Propagation)",
        "探索-利用 (Exploration-Exploitation)"
      ],
      "answer": 0,
      "description": "經驗回放會儲存歷史資料，再隨機抽樣訓練，降低樣本之間的相關性並提升學習穩定度。"
    }
  ]